{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5be5a7b-6024-4dba-9e98-b7b67d423528",
   "metadata": {},
   "source": [
    "### Class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b92afb8-da0a-41f5-8ee6-0751a3d435bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import operator\n",
    "import itertools as it\n",
    "import datetime\n",
    "import statistics\n",
    "from collections import defaultdict\n",
    "\n",
    "ALLOWED_COL_PROPERTIES = ['dtype','long_name','col_print_length','key','aggregation_func']\n",
    "\n",
    "def nunique(values: list):\n",
    "    \"\"\"Count of unique values\"\"\"\n",
    "    return lambda x: len(set(x))\n",
    "\n",
    "def count(values: list):\n",
    "    \"\"\"Count non-missing values\"\"\"\n",
    "    return len(x for x in values if x is not None)\n",
    "\n",
    "agg_functions ={'nunique':nunique,'mean':statistics.mean,'sum':sum,'median':statistics.median,'min':min,'max':max,'std':statistics.stdev,'var':statistics.variance,'count':count,'len':len}\n",
    "\n",
    "def pretty_string(string,color,length=None):\n",
    "    \"\"\"Trim to length and change color of provided string.\n",
    "\n",
    "    Given string is first trimmed to requested length, then color\n",
    "    formatting is applied and the result returned.\n",
    "    Trimming is performed by keepting the first [length] characters.\n",
    "    It is useful to trim strings before formatting because\n",
    "    formatting is performed by adding special characters thus\n",
    "    making the string's length more than the visible characters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    string : str\n",
    "             String which will be returned trimmed and formatted.\n",
    "    color : str\n",
    "            Color to apply to the string. Available colors are\n",
    "            red, green, yellow, blue, magenta, cyan.\n",
    "    length : int\n",
    "             Length to which the provided string will be trimmed\n",
    "             be removing characters from the right. This length\n",
    "             is for the visible characters only and does not count\n",
    "             the special formatting characters that are added\n",
    "             by this function.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    Given string 'lengthy_column_name' apply blue font and return\n",
    "    string that is only 4 characters long i.e. \"leng\"\n",
    "    \n",
    "    >>> pretty_string('lengthy_column_name','blue',4)\n",
    "\n",
    "    \"\"\"\n",
    "    colors_dict = {\n",
    "        'red':31,\n",
    "        'green':32,\n",
    "        'yellow':33,\n",
    "        'blue':34,\n",
    "        'magenta':35,\n",
    "        'cyan':36,\n",
    "    }\n",
    "    # This assures that only the visible characters are trimmed and not the whole string including formatting\n",
    "    if length==None:\n",
    "        return f\"\\033[{colors_dict[color]}m{string}\\033[0m\"\n",
    "    else:\n",
    "        return f\"\\033[{colors_dict[color]}m{string[:length]}\\033[0m\"\n",
    "    \n",
    "def is_iterable(obj):\n",
    "    \"\"\"Check whether obj is iterable.\"\"\"\n",
    "    try:\n",
    "        iter(obj)\n",
    "        return True\n",
    "    except TypeError:\n",
    "        return False\n",
    "\n",
    "def element_wise_comparison(func, list_1, list_2):\n",
    "    \"\"\"Compare list_1 and list_2 using func and return a list of Bool\n",
    "\n",
    "    Takes Python lists or tuples and outputs Python lists. list_2 may be a scalar.\n",
    "\n",
    "    \"\"\"\n",
    "    if not is_iterable(list_1):\n",
    "        raise TypeError(\"list_1 must be of the type 'List'\")\n",
    "    if isinstance(list_2, (int, float, str, datetime.datetime)) :\n",
    "        # Compare list list_1 to a value list_2\n",
    "        return [func(x,list_2) for x in list_1]\n",
    "    elif is_iterable(list_2):\n",
    "        # Compare list to a list if their lengths are compatible\n",
    "        if len(list_1) != len(list_2):\n",
    "            raise ValueError(\"Lists have incompatible lengths\")\n",
    "        return [func(x,y) for x, y in zip(iter(list_1), iter(list_2))]\n",
    "    else:\n",
    "        raise TypeError(\"Can only compare against the types 'Int,' 'Float,' 'Str,' or 'List'\")\n",
    "\n",
    "def aggregate_ignore_none(iterable, aggregation_func):\n",
    "    \"\"\"\n",
    "    Aggregate function that ignores None values.\n",
    "    \n",
    "    If all values are None, returns None.\n",
    "    \"\"\"\n",
    "    filtered_values = [value for value in iterable if value is not None]\n",
    "    if not filtered_values:\n",
    "        return None\n",
    "    return aggregation_func(filtered_values)\n",
    "\n",
    "class Category:\n",
    "    \"\"\"Data format for categorical data\n",
    "\n",
    "    INCOMPLETE.  Will include list of categories and dict for encoding.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        return None\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.data\n",
    "        \n",
    "    def __format__(self,fmt):\n",
    "        return f\"{self.data:{fmt}}\"\n",
    "\n",
    "class DataColumn:\n",
    "    \"\"\"Represents a column of a DataFrame.\n",
    "\n",
    "    Stores the column's values and additional metadata\n",
    "    to describe column properties. DataColumn is subscriptable.\n",
    "    See examples below.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    data : list\n",
    "           Ordered ist of values belonging to this column.\n",
    "    dtype : data type\n",
    "            The type of the data in this column. For example\n",
    "            str, int, Category.\n",
    "    long_name : str\n",
    "                Long name of the column intended for human\n",
    "                understanding. Long_names can be useful\n",
    "                for interpreting each column as the names\n",
    "                that arae printed by DataFrame by default\n",
    "                are short names and should emphasize brevity\n",
    "                over meaningfulness.\n",
    "    col_print_length : int\n",
    "                The lengh (in number of characters) used when\n",
    "                printing this column. Column label and values\n",
    "                will be truncated to fit this length. \n",
    "                Calculaated by considering the min and max\n",
    "                column widths as well as the column name\n",
    "                and all values in the column.\n",
    "    key : bool\n",
    "          Boolean value indicating whether this column\n",
    "          is a key or not. Key columns may not have missing \n",
    "          values and are used by the DataFrame for aggregations.\n",
    "          Key columns are ignored when DataFrame exports data\n",
    "          for analysis by default.\n",
    "    aggregation_func : callable\n",
    "                A callable that must accept an iterable\n",
    "                and return a single value. This is used \n",
    "                by DataFrame to aggregate the data.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    apply(func)\n",
    "    sum()\n",
    "    min()\n",
    "    max()\n",
    "    mean()\n",
    "    median()\n",
    "    median_low()\n",
    "    median_high()\n",
    "    mode()\n",
    "    std()\n",
    "    var()\n",
    "    pstd()\n",
    "    pvariance()\n",
    "    cov()\n",
    "    cor()\n",
    "    lr(other)\n",
    "    set_type(new_type)\n",
    "    isna()\n",
    "    any_na()\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    Create new column with four values:\n",
    "    >>> col = DataColumn([0,9,8,7])\n",
    "    Select first two elements from column's data:\n",
    "    >>> col[:2]\n",
    "    Returns list [0,9].\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, data, col_properties:dict=None):\n",
    "        \"\"\"Initiate new column\n",
    "        \n",
    "        New column containing the provided data and properties,\n",
    "        if provided. If no col_properties is passed, initiates \n",
    "        all column properties with the value of None.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : list\n",
    "               List of the column's values.\n",
    "        col_properties : dict\n",
    "                         Property: value pairs. \n",
    "        \n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        # Initiate empty properites\n",
    "        for prop in ALLOWED_COL_PROPERTIES:\n",
    "            self._set_properties({prop:None})\n",
    "        # Set the passed properties\n",
    "        if col_properties != None:\n",
    "            self._set_properties(col_properties)\n",
    "        return\n",
    "            \n",
    "    def _set_properties(self, property_dict):\n",
    "        \"\"\"Set column property\"\"\"\n",
    "        if isinstance(property_dict, dict):\n",
    "            for attr_name, attr_val in property_dict.items():\n",
    "                if attr_name == 'aggregation_func':\n",
    "                    if isinstance(attr_val,str):\n",
    "                        setattr(self, attr_name, agg_functions[attr_val])\n",
    "                    else:\n",
    "                        setattr(self,attr_name,attr_val)\n",
    "                else:\n",
    "                    setattr(self, attr_name, attr_val)\n",
    "        else:\n",
    "            raise TypeError(\"property_dict parameter must be of the type 'Dict'\")\n",
    "        return\n",
    "\n",
    "    def _get_property(self, property_name):\n",
    "        \"\"\"Extract a property value\"\"\"\n",
    "        try:\n",
    "            return getattr(self,property_name,None)\n",
    "        except:\n",
    "            raise ValueError(f\"Property {property_name} not found\")\n",
    "\n",
    "    def _get_all_properties(self):\n",
    "        \"\"\"\n",
    "        Extract all properties\n",
    "        \n",
    "        Form a dicct of dicts that can be used to recreate this column i.e. in DataColumn\n",
    "        class initialization.\n",
    "        \n",
    "        \"\"\"\n",
    "        all_properties = {}\n",
    "        for prop in ALLOWED_COL_PROPERTIES:\n",
    "            all_properties[prop] = self._get_property(prop)\n",
    "        return all_properties\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.data[key]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __add__(self, other):\n",
    "        if isinstance(other, int) or isinstance(other, float):\n",
    "            return DataColumn([operator.add(x, other) for x in self.data])\n",
    "        elif is_iterable(other):\n",
    "            if len(self) != len(other):\n",
    "                raise ValueError(\"Columns have incompatible lengths\")\n",
    "            return DataColumn([x + y for x, y in zip(iter(self),iter(other))])\n",
    "        else:\n",
    "            raise TypeError(\"Operands must be iterable or 'Int,' or 'Float'\")\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        if isinstance(other, int) or isinstance(other, float):\n",
    "            return DataColumn([operator.sub(x, other) for x in self.data])\n",
    "        elif is_iterable(other):\n",
    "            if len(self) != len(other):\n",
    "                raise ValueError(\"Columns have incompatible lengths\")\n",
    "            return DataColumn([x - y for x, y in zip(iter(self),iter(other))])\n",
    "        else:\n",
    "            raise TypeError(\"Operands must be iterable or 'Int,' or 'Float'\")\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        if isinstance(other, int) or isinstance(other, float):\n",
    "            return DataColumn([operator.mul(x, other) for x in self.data])\n",
    "        elif is_iterable(other):\n",
    "            if len(self) != len(other):\n",
    "                raise ValueError(\"Columns have incompatible lengths\")\n",
    "            return DataColumn([x * y for x, y in zip(iter(self),iter(other))])\n",
    "        else:\n",
    "            raise TypeError(\"Operands must be iterable or 'Int,' or 'Float'\")\n",
    "\n",
    "    def __truediv__(self, other):\n",
    "        if isinstance(other, int) or isinstance(other, float):\n",
    "            if other==0:\n",
    "                raise ValueError(\"Div by zero is not allowed\")\n",
    "            return DataColumn([operator.truediv(x, other) for x in self.data])\n",
    "        elif is_iterable(other):\n",
    "            if len(self) != len(other):\n",
    "                raise ValueError(\"Columns have incompatible lengths\")\n",
    "            if 0 in other:\n",
    "                raise ValueError(\"Encountered division by zero\")\n",
    "            return DataColumn([x / y for x, y in zip(iter(self),iter(other))])\n",
    "        else:\n",
    "            raise TypeError(\"Can only divide by the types 'Int,' or 'Float'\")\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return DataColumn(element_wise_comparison(operator.eq,self, other))\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return DataColumn(element_wise_comparison(operator.lt,self, other))\n",
    "\n",
    "    def __le__(self, other):\n",
    "        \n",
    "        return DataColumn(element_wise_comparison(operator.le,self, other))\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        \n",
    "        return DataColumn(element_wise_comparison(operator.ne,self, other))\n",
    "\n",
    "    def __ge__(self, other):\n",
    "        \n",
    "        return DataColumn(element_wise_comparison(operator.ge,self, other))\n",
    "\n",
    "    def __gt__(self, other):\n",
    "        \n",
    "        return DataColumn(element_wise_comparison(operator.gt,self, other))\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"DataColumn of size {len(self)}\"\n",
    "\n",
    "    def as_list(self):\n",
    "        \"\"\"Return this column's values as a list\"\"\"\n",
    "        return self.data\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.data)\n",
    "\n",
    "    def apply(self, func):\n",
    "        \"\"\"Map func onto this column's values\"\"\"\n",
    "        return DataColumn(list(map(func,self.data)))\n",
    "\n",
    "    def sum(self):\n",
    "        \"\"\"Return the sum of this column's values\"\"\"\n",
    "        return sum(self.data)\n",
    "\n",
    "    def min(self):\n",
    "        \"\"\"Return the smallest of this column's values\"\"\"\n",
    "        return min(self.data)\n",
    "\n",
    "    def max(self):\n",
    "        \"\"\"Return the largest of this column's values\"\"\"\n",
    "        return max(self.data)\n",
    "\n",
    "    def mean(self):\n",
    "        \"\"\"Return the mean of this column's values\"\"\"\n",
    "        return statistics.mean(self.data)\n",
    "\n",
    "    def median(self):\n",
    "        \"\"\"Return the median of this column's values\"\"\"\n",
    "        return statistics.median(self.data)\n",
    "\n",
    "    def median_low(self):\n",
    "        \"\"\"Return the low median of this column's values\"\"\"\n",
    "        return statistics.median_low(self.data)\n",
    "\n",
    "    def median_high(self):\n",
    "        \"\"\"Return the high median of this column's values\"\"\"\n",
    "        return statistics.median_high(self.data)\n",
    "\n",
    "    def mode(self):\n",
    "        \"\"\"Return the mode of this column's values\"\"\"\n",
    "        return statistics.mode(self.data)\n",
    "\n",
    "    def std(self):\n",
    "        \"\"\"Return the sample standard deviation of this column's values\"\"\"\n",
    "        return statistics.stdev(self.data)\n",
    "\n",
    "    def var(self):\n",
    "        \"\"\"Return the sample variance of this column's values\"\"\"\n",
    "        return statistics.variance(self.data)\n",
    "\n",
    "    def pstd(self):\n",
    "        \"\"\"Return the population standard deviation of this column's values\"\"\"\n",
    "        return statistics.pstdev(self.data)\n",
    "\n",
    "    def pvariance(self):\n",
    "        \"\"\"Return the population variance of this column's values\"\"\"\n",
    "        return statistics.pvariance(self.data)\n",
    "\n",
    "    def cov(self,other):\n",
    "        \"\"\"Return the covariance of this column with other column\"\"\"\n",
    "        if isinstance(other, DataColumn):\n",
    "            return statistics.covariance(self.data,other.data)\n",
    "        else:\n",
    "            raise TypeError(\"Can only compare to another DataColumn\")\n",
    "\n",
    "    def cor(self,other):\n",
    "        \"\"\"Return the correlation of this column with other column\"\"\"\n",
    "        if isinstance(other, DataColumn):\n",
    "            return statistics.correlation(self.data,other.data)\n",
    "        else:\n",
    "            raise TypeError(\"Can only compare to another DataColumn\")\n",
    "\n",
    "    def lr(self,other):\n",
    "        \"\"\"Linear regression against another column.\n",
    "\n",
    "        Regress this column on another column and return slope and intercept.\n",
    "        https://docs.python.org/3/library/statistics.html\n",
    "\n",
    "        Returns slope, intercept\n",
    "        \"\"\"\n",
    "        if isinstance(other, DataColumn):\n",
    "            return statistics.linear_regression(other.data,self.data)\n",
    "        else:\n",
    "            raise TypeError(\"Can only compare to another DataColumn\")\n",
    "\n",
    "    def as_type(self, new_type):\n",
    "        \"\"\"Returns DataColumn equivalent to this but with values cast to new_type\"\"\"\n",
    "        casted_values = []\n",
    "        for val in self.data:\n",
    "            try:\n",
    "                if val==None:\n",
    "                    casted_val=None\n",
    "                else:\n",
    "                    casted_val = new_type(val)\n",
    "                casted_values.append(casted_val)\n",
    "            except (TypeError, ValueError) as e:\n",
    "                raise ValueError(f\"Cannon cast {val} to {new_type}: {e}\")\n",
    "        col_props = self._get_all_properties()\n",
    "        return DataColumn(casted_values,col_properties=col_props)\n",
    "\n",
    "    def isna(self):\n",
    "        \"\"\"Return list of bools indicating missing values\"\"\"\n",
    "        return list(map(lambda x: x==None,self.data))\n",
    "\n",
    "    def any_na(self):\n",
    "        \"\"\"Return True if any value is None\"\"\"\n",
    "        return any(map(lambda x: x == None,self.data))\n",
    "\n",
    "    def fillna(self,fill_val):\n",
    "        \"\"\"Return DataColumn with fill_value in place of missing values\"\"\"\n",
    "        new_values = list(map(lambda x: fill_val if x==None else x,self.data))\n",
    "        col_props = self._get_all_properties()\n",
    "        return DataColumn(new_values,col_properties=col_props)\n",
    "        \n",
    "class DataFrame:\n",
    "    '''\n",
    "    Simplistic DataFrame\n",
    "\n",
    "    Consists of columns represented by DataColumn class.\n",
    "\n",
    "    Functions\n",
    "    ---------\n",
    "    read_csv\n",
    "    to_csv\n",
    "    apply\n",
    "\n",
    "    '''\n",
    "    def __init__(self,data=None,dtypes=None,col_properties=None,row_index=None,row_index_labels=None):\n",
    "        \"\"\"\n",
    "        Initiate new DataFrame, either empty or from values\n",
    "        \n",
    "        Returns empty DataFrame if data is None. If data is provided,\n",
    "        populates the dataframe accordingly. If dtypes are provdied,\n",
    "        casts and sets the values accordingly. If col_properties are\n",
    "        provided, sets the properties accordingly.\n",
    "        Since dtypes can also be specified in col_properties,\n",
    "        if both dtypes and col_properties were given, returns error.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : dict {str : iterable}\n",
    "               Keys are used as names (short names) for the frame's\n",
    "               columns. Defaults to None.\n",
    "        dtypes : dict {str : type}\n",
    "                 Datatypes to use for each column. Defaults to None.\n",
    "        col_properties : dict {str : dict}\n",
    "                         For each column, provided a dict of column\n",
    "                         properties. Defaults to None.\n",
    "        \n",
    "        \"\"\"\n",
    "        dtypes_provided = isinstance(dtypes,dict)\n",
    "        col_props_provided = isinstance(col_properties,dict)\n",
    "        # Make sure that only one of dtypes and col_propperties was provided\n",
    "        # since col_properties can include dtypes.\n",
    "        if dtypes_provided and col_props_provided:\n",
    "            raise TypeError(\"Can only specify one of the parameters dtypes and col_properties\")\n",
    "        values_len = -1\n",
    "        # Set default values for internal parameters\n",
    "        #self._default_col_print_length = 10\n",
    "        self._max_col_print_length = 10\n",
    "        self._min_col_print_length = 5\n",
    "        self.rows = NestedDict(assume_sorted=True)\n",
    "        self._data = []\n",
    "        self.columns = {} # keys are short names; col_properties includes long_name\n",
    "        self.row_index = NestedDict(assume_sorted=True)\n",
    "        self.row_index_labels = []\n",
    "        if data==None:\n",
    "            pass\n",
    "        elif isinstance(data,dict):\n",
    "            col_idx = 0 # iterate column index\n",
    "            for key, values in data.items():\n",
    "                # Check column lengths compatibiilty\n",
    "                if values_len == -1:\n",
    "                    values_len = len(values)\n",
    "                else:\n",
    "                    if len(values) != values_len:\n",
    "                        raise ValueError(\"Columns have incompatible lengths\")\n",
    "                # Check if dtypes were given and store data values\n",
    "                if dtypes_provided:\n",
    "                    self._data.append(DataColumn([dtypes[key](val) for val in values]))\n",
    "                    self._data[col_idx]._set_properties({'dtype':dtypes[key]})\n",
    "                elif col_props_provided:\n",
    "                    self._data.append(DataColumn(values))\n",
    "                    self._data[col_idx]._set_properties(col_properties[key])\n",
    "                else:\n",
    "                    self._data.append(DataColumn(values))\n",
    "                # Add column to columns dict\n",
    "                self.columns[key] = col_idx\n",
    "                col_idx += 1\n",
    "            self._update_col_lengths()\n",
    "            self.rows = row_index\n",
    "            self.row_index_labels = row_index_labels\n",
    "        else:\n",
    "            raise TypeError(\"Data must be of the type'Dict'\")\n",
    "        return\n",
    "\n",
    "    def _update_col_lengths(self,col=None):\n",
    "        \"\"\"Update the printing width of the column\"\"\"\n",
    "        if col==None:\n",
    "            for col_label, col_idx in self.columns.items():\n",
    "                new_length = min(self._max_col_print_length,max([len(str(x))+1 for x in self._data[col_idx]]))\n",
    "                new_length = max(new_length,len(col_label)+1)\n",
    "                new_length = max(new_length,self._min_col_print_length)\n",
    "                self.set_property('col_print_length',{col_label:new_length})\n",
    "            return\n",
    "        else:\n",
    "            col_label = col\n",
    "            col_idx = self.columns[col_label]\n",
    "            new_length = min(self._max_col_print_length,max([len(str(x))+1 for x in self._data[col_idx]]))\n",
    "            new_length = max(new_length,len(col_label)+1)\n",
    "            new_length = max(new_length,self._min_col_print_length)\n",
    "            self.set_property('col_print_length',{col_label:new_length})\n",
    "            return\n",
    "            \n",
    "    def read_csv(self, file_path):\n",
    "        \"\"\"\n",
    "        Read data from a csv file.\n",
    "        \n",
    "        Populates this frame, if empty, with data read from the csv file file_path.\n",
    "        Column headers from the file will be stored as the short column names. If you\n",
    "        want to replace them, use set_short_col_names method of this frame in a consequent\n",
    "        step.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        file_path : str\n",
    "                    Path to a csv file.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Make sure this frame is empty\n",
    "        if len(self.columns) > 0:\n",
    "            raise RuntimeError(\"Attemped to overwrite current data with read_csv\")\n",
    "        # Read the file\n",
    "        with open(file_path, 'r', newline='') as file:\n",
    "            csv_reader = csv.reader(file,skipinitialspace=True) # https://docs.python.org/3/library/csv.html\n",
    "            columns = next(csv_reader)\n",
    "            for i, col_label in enumerate(columns):\n",
    "                self.columns[col_label] = i\n",
    "            data = []\n",
    "            for row in csv_reader:\n",
    "                processed_row = [None if value == '' else value for value in row]\n",
    "                data.append(processed_row)\n",
    "        self._data = list(zip(*data)) # transpose\n",
    "        # Transform into DataColumn types\n",
    "        for col_idx, col_data in enumerate(self._data):\n",
    "            self._data[col_idx] = DataColumn(col_data)\n",
    "        del data;\n",
    "        self._update_col_lengths()\n",
    "        return\n",
    "\n",
    "    def to_csv(self, file_path):\n",
    "        \"\"\"\n",
    "        Store this frame's data into a csv file\n",
    "        \n",
    "        INCOMPLETE, need to fix _data and address the questions in the comments.\n",
    "        \n",
    "        \"\"\"\n",
    "        with open(file_path, 'w', newline='') as file: # newline????\n",
    "            csv_writer = csv.writer(file) # https://docs.python.org/3/library/csv.html\n",
    "            csv_writer.writerow(list(self.columns.keys()))\n",
    "            csv_writer.writerows(self._data)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Select elements from the DataFrame\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        Assume the following DataFrame df:\n",
    "          | col_a  | col_b  |  col_val   | \n",
    "        i |    UNK |    UNK |        UNK | \n",
    "        ----------------------------------\n",
    "        0 |      1 |     10 |        0.2 | \n",
    "        1 |      1 |     10 |        0.3 | \n",
    "        2 |      1 |     10 |        0.5 | \n",
    "        3 |      1 |     10 |        0.4 | \n",
    "        4 |      1 |     10 |        0.3 | \n",
    "        ...\n",
    "        \n",
    "        Column selectors:\n",
    "        df['col_a'] - column col_a\n",
    "        To select multiple columns, use a list.  Do not use a tuple.\n",
    "        df[['col_a','col_val']] - columns col_a, col_val\n",
    "\n",
    "        Column and row selectors:\n",
    "        df[:10, ['col_a','col_b']] - first 10 rows, columns col_a, col_b\n",
    "        df[[1,4], ['col_a','col_b']] - rows 1 and 4, columns col_a, \n",
    "        df[[True,False,False,True], ] - rows 0 and 3, all columns\n",
    "        df[[1,4], ['col_a',2]] - rows 1 and 4, columns col_a, col_val\n",
    "        \n",
    "        \"\"\"\n",
    "        all_cols_properties = {}\n",
    "        if isinstance(key,tuple):\n",
    "            new_data_dict = {} # Store the selected data, then use it to create and return new DataFrame\n",
    "            new_cols = []\n",
    "            use_all_cols = False\n",
    "            # Extract row selector\n",
    "            if isinstance(key[0],DataColumn):\n",
    "                row_selector = key[0].data\n",
    "            else:\n",
    "                row_selector = key[0]\n",
    "            # Extract column selector\n",
    "            ## If empty, use all columns\n",
    "            try:\n",
    "                key[1]\n",
    "            except:\n",
    "                use_all_cols=True\n",
    "            if use_all_cols:\n",
    "                new_cols = list(self.columns.keys())\n",
    "            elif isinstance(key[1],(list,tuple)):\n",
    "                # if column selector is iterable, extract values into new_cols list\n",
    "                new_cols = list(key[1])\n",
    "            else:\n",
    "                # otherwise create a list with just the one element\n",
    "                new_cols.append(key[1])\n",
    "            # Make sure that the new_list contains column labels, not indices\n",
    "            for i, col in enumerate(new_cols):\n",
    "                if isinstance(col,str):\n",
    "                    pass\n",
    "                elif isinstance(col,int):\n",
    "                    new_cols[i] = list(self.columns.keys())[col]\n",
    "                else:\n",
    "                    raise TypeError(\"Column selector must contain str or int values.\")\n",
    "            # Extract data here\n",
    "            ## For each selected column...\n",
    "            for col_label, col_idx in self.columns.items():\n",
    "                if col_label in new_cols:\n",
    "                    if isinstance(row_selector,list):\n",
    "                        if isinstance(row_selector[0],bool):\n",
    "                            new_data_dict[col_label] = [x for x, is_selected in zip(self._data[col_idx],row_selector) if is_selected]\n",
    "                        elif isinstance(row_selector[0],int):\n",
    "                            new_data_dict[col_label] = [self._data[col_idx][x] for x in row_selector]\n",
    "                    else:\n",
    "                        new_data_dict[col_label] = self._data[col_idx][row_selector]\n",
    "                    all_cols_properties[col_label] = self._data[col_idx]._get_all_properties()\n",
    "            # Extract index info so it can be passed to the new frame\n",
    "            new_row_index_labels = [col for col in self.row_index_labels if col in new_data_dict.keys()]\n",
    "            return DataFrame(new_data_dict,col_properties=all_cols_properties,row_index_labels=new_row_index_labels) # Do not replicate the same row_index as in self because it may be based on columns that were not selected.  row_index_labels is ok\n",
    "        elif isinstance(key, int):\n",
    "            return DataColumn(self._data[key],col_properties=self._data[key]._get_all_properties())\n",
    "        elif isinstance(key, str):\n",
    "            try:\n",
    "                col_idx = self.columns[key]\n",
    "                return DataColumn(self._data[col_idx],col_properties=self._data[col_idx]._get_all_properties())\n",
    "            except ValueError:\n",
    "                raise KeyError(f\"Column '{key}' not found\")\n",
    "        elif isinstance(key, list):\n",
    "            new_data_dict = {} # Store the selected data, then use it to create and return new DataFrame\n",
    "            # extract values into new_cols list\n",
    "            new_cols = list(key)\n",
    "            # Make sure that the new_list contains column indices, not labels\n",
    "            for i, col in enumerate(new_cols):\n",
    "                if isinstance(col,str):\n",
    "                    new_cols[i] = self.columns[col]\n",
    "                elif isinstance(col,int):\n",
    "                    pass\n",
    "                else:\n",
    "                    raise TypeError(\"Column selector must contain str or int values.\")\n",
    "            # For each selected column...\n",
    "            for col_label, col_idx in self.columns.items():\n",
    "                if col_idx in new_cols:\n",
    "                    new_data_dict[col_label] = self._data[col_idx]\n",
    "                    all_cols_properties[col_label] = self._data[col_idx]._get_all_properties()\n",
    "            # Extract index info so it can be passed to the new frame\n",
    "            new_row_index_labels = [col for col in self.row_index_labels if col in new_data_dict.keys()]\n",
    "            return DataFrame(new_data_dict,col_properties=all_cols_properties,row_index_labels=new_row_index_labels)\n",
    "\n",
    "    def __setitem__(self, key, new_col_values):\n",
    "        \"\"\"\n",
    "        Modify existing column or create new column.\n",
    "        \n",
    "        New values must be either DataColumn, list, int, float, str, datetime, or bool.\"\"\"\n",
    "        required_col_len = len(self._data[0])\n",
    "        if isinstance(key, str):\n",
    "            col_label = key\n",
    "            # If exists, find the column index, otherwise check if possible (corrent length) to create the column\n",
    "            if key in self.columns:\n",
    "                # Column exists\n",
    "                col_idx = self.columns[key]\n",
    "            else:\n",
    "                col_idx = len(self.columns) # b/c current length is 1 greater than current rightmost idn\n",
    "                self.columns[key] = len(self.columns)\n",
    "                self._data.append(DataColumn([None]*required_col_len))\n",
    "        elif isinstance(key, int):\n",
    "            col_idx = key\n",
    "            col_label = list(self.columns.keys())[col_idx]\n",
    "        else:\n",
    "            raise TypeError(\"Key must be of the types 'Str' or 'Int'\")\n",
    "        if isinstance(new_col_values, DataColumn):\n",
    "            if len(self._data[col_idx]) != len(new_col_values):\n",
    "                raise ValueError(\"Columns have incompatible lengths\")\n",
    "            self._data[col_idx] = new_col_values\n",
    "        elif isinstance(new_col_values, list):\n",
    "            if len(self._data[col_idx]) != len(new_col_values):\n",
    "                raise ValueError(\"Columns have incompatible lengths\")\n",
    "            # Get the properties of the column being replaced and create new column with the same properties\n",
    "            col_props = self._data[col_idx]._get_all_properties()\n",
    "            self._data[col_idx] = DataColumn(new_col_values,col_properties=col_props)\n",
    "        elif isinstance(new_col_values,(int,str,float,bool,datetime,Category)):\n",
    "            # Get the properties of the column being replaced and create new column with the same properties\n",
    "            col_props = self._data[col_idx]._get_all_properties()\n",
    "            self._data[col_idx] = DataColumn([new_col_values]*required_col_len,col_properties=col_props)\n",
    "        else:\n",
    "            raise TypeError(\"New column values must be a list, DataColumn, Str, Int, Bool, or Datetime.\")\n",
    "        self._update_col_lengths(col=col_label)\n",
    "        return\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._data[0])\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"DataFrame with {len(self.columns)} columns and {len(self)} rows\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self._data)\n",
    "\n",
    "    def show(self,start_row=0,nrows=5,show_index=True):\n",
    "        \"\"\"Print the requested rows of data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        start_row : int\n",
    "                    First row to be printed, default: 0.\n",
    "        nrows : int\n",
    "                How many rows to print in total, default: 5.\n",
    "        show_index : bool\n",
    "                     Whether to print index.\n",
    "        \"\"\"\n",
    "        display_data = [] # each element to represent a row (instead of col as is in self._data\n",
    "        prefix_extra_len = len(str(start_row+nrows))-1\n",
    "        prefix_header1 = \"| \" \n",
    "        prefix_header2 = \"| \"\n",
    "        prefix_header3 = \"| \"\n",
    "        prefix_line = \"--\"\n",
    "        prefix_data = \"f'| '\"\n",
    "        # Prepare prefix\n",
    "        if show_index:\n",
    "            prefix_header1 = f\"{' ':>{1+prefix_extra_len}} |\"\n",
    "            prefix_header2 = f\"{' ':>{1+prefix_extra_len}} |\"\n",
    "            prefix_header3 = f\"{'i':>{1+prefix_extra_len}} |\"\n",
    "            prefix_line = \"-\"*(3+prefix_extra_len)\n",
    "            prefix_data=\"f'{data_idx:>{1+prefix_extra_len}} |'\"\n",
    "        # Slice rows\n",
    "        for col in self._data:\n",
    "            col = list(it.islice(col,start_row,start_row+nrows))\n",
    "            display_data.append(col)\n",
    "        # Transpose for  printing row by row\n",
    "        display_data = list(zip(*display_data))\n",
    "        # Print header\n",
    "        ## Row 1 (short name)\n",
    "        row_1_string = \"\"\n",
    "        row_1_string += prefix_header1 + \" \"\n",
    "        for col_label, col_idx in self.columns.items():\n",
    "            col_width = self._data[col_idx].col_print_length\n",
    "            row_1_string += f\"{col_label:^{col_width}}\" + ' | '\n",
    "        print(row_1_string)\n",
    "        ## Row 2 (dtypes)\n",
    "        print(prefix_header2,end=' ')\n",
    "        for col_label, col_idx in self.columns.items():\n",
    "            try:\n",
    "                dtype = self._data[col_idx].dtype\n",
    "                col_width = self._data[col_idx].col_print_length\n",
    "                text_to_print = \"\"\n",
    "                if dtype==str:\n",
    "                    text_to_print = pretty_string(f\"{'str':>{col_width}}\",'magenta')\n",
    "                elif dtype==int or dtype==float:\n",
    "                    text_to_print = pretty_string(f\"{'num':>{col_width}}\",'green')\n",
    "                elif dtype==Category:\n",
    "                    text_to_print = pretty_string(f\"{'C':>{col_width}}\",'yellow') ########################### Need to specify whether dummiefied already or not and how many cats\n",
    "                else:\n",
    "                    text_to_print = pretty_string(f\"{'UNK':>{col_width}}\",'red')\n",
    "                print(text_to_print,end = ' | ')\n",
    "            except:\n",
    "                pass\n",
    "        ## Row 3 (aggregation summary)\n",
    "        print()\n",
    "        print(prefix_header3,end=' ')\n",
    "        for col_label, col_idx in self.columns.items():\n",
    "            col_width = self._data[col_idx].col_print_length\n",
    "            # If this is a key column, indicate that, otherwise get the aggregation function's name\n",
    "            if self._data[col_idx].key:\n",
    "                agg_funct_string = \"*\"\n",
    "            else:\n",
    "                try:\n",
    "                    agg_funct_string = self._data[col_idx].aggregation_func.__name__\n",
    "                except AttributeError:\n",
    "                    agg_funct_string = \"\"\n",
    "            warning_string = \" !\" if sum(self._data[col_idx].isna())>0 else \"\"\n",
    "            agg_funct_string = agg_funct_string[:(col_width-len(warning_string))] # shorten the string if necessary\n",
    "            \n",
    "            text_to_print = f\"{agg_funct_string:>{col_width-len(warning_string)}}\"+pretty_string(warning_string,'red')\n",
    "            print(text_to_print,end = ' | ')\n",
    "            #except:\n",
    "            #    pass\n",
    "        \n",
    "        # Break line\n",
    "        print(\"\\n\"+prefix_line+(\"-\"*(len(row_1_string)-1-len(prefix_line))))\n",
    "        # Print rows, one col at a time\n",
    "        for r in range(len(display_data)):\n",
    "            data_idx = r + start_row # used in eval(prefix_data)\n",
    "            print(eval(prefix_data),end=' ')\n",
    "            for col_idx, col_val in enumerate(display_data[r]):\n",
    "                text_to_print = \"\" # text to print for the current column, formatted below\n",
    "                col_width = self._data[col_idx].col_print_length\n",
    "                if isinstance(col_val,float):\n",
    "                    text_to_print=f\"{col_val:>{col_width},.1f}\"\n",
    "                elif col_val==None:\n",
    "                    text_to_print = pretty_string(f\"{'--':>{col_width}}\",'red')\n",
    "                elif isinstance(col_val,Category):\n",
    "                    text_to_print=f\"{col_val:>{col_width}}\"\n",
    "                elif isinstance(col_val,str):\n",
    "                    text_to_print=f\"{col_val[:col_width]:>{col_width}}\"\n",
    "                else:\n",
    "                    text_to_print=f\"{col_val:>{col_width}}\"\n",
    "                print(text_to_print,end = ' | ')\n",
    "            print('')\n",
    "        # Return descriptive string\n",
    "        return f\"DataFrame with {len(self.columns)} columns and {len(self._data[0])} rows\"\n",
    "\n",
    "    def set_property(self,property_type,new_properties):\n",
    "        \"\"\"Set the values of a property for one or more columns.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        property_type : str\n",
    "                        Name of the property to be set/changed\n",
    "        new_properties : dict\n",
    "                         A dict of the form short_col_label : value\n",
    "                         to be used as the mapping of new values for\n",
    "                         the property for the column indicated\n",
    "                         by the dict's key\n",
    "        \"\"\"\n",
    "        # Check that this is a property that can be set/modified:\n",
    "        if property_type not in ALLOWED_COL_PROPERTIES:\n",
    "            raise ValueError(f\"Property_type must be one of {ALLOWED_COL_PROPERTIES}\")\n",
    "        # Make sure that dict was passed\n",
    "        if not isinstance(new_properties, dict):\n",
    "            raise TypeError(f\"New_properies must be a dict\")\n",
    "        # Iterate over dict and set each column's property to the value\n",
    "        # Column properties are stored within this DataFrame, not with Column class\n",
    "        for col_name, prop_value in new_properties.items():\n",
    "            col_idx = self.columns[col_name]\n",
    "            self._data[col_idx]._set_properties({property_type:prop_value})\n",
    "            # In addition, if dtype was changed, cast the column into the new dtype\n",
    "            if property_type == 'dtype':\n",
    "                self._data[col_idx] = self._data[col_idx].as_type(prop_value)\n",
    "        return\n",
    "\n",
    "    def set_short_col_names(self,new_names,promote_current_to_long_names=False):\n",
    "        \"\"\"\n",
    "        Set or update columns' short names.\n",
    "\n",
    "        Set short names for DataFrame's columns as indicated by new_names. In addition,\n",
    "        if promote_current_to_long_names is True, current short names will be promoted\n",
    "        to long names. Short names are used when the DataFrame is printed, they should\n",
    "        emphasize brevity over clarity.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        new_names : dict\n",
    "                    Dictionary of current and new names.\n",
    "        promote_current_to_long_names : bool\n",
    "                                        Whether to promote the current short names \n",
    "                                        to new long names. Default: False.\n",
    "\n",
    "        \"\"\"\n",
    "        # Make sure none of the new names is not already taken\n",
    "        for new_label in new_names.values():\n",
    "            if new_label in self.columns.keys():\n",
    "                raise ValueError(f\"Column {new_label} already exists\")\n",
    "        new_long_names = {}\n",
    "        if not isinstance(new_names,dict):\n",
    "            raise TypeError(\"new_names must be a dict\")\n",
    "        else:\n",
    "            for cur_label, new_label in new_names.items():\n",
    "                if promote_current_to_long_names:\n",
    "                    new_long_names[new_label] = cur_label\n",
    "                self.columns[new_label] = self.columns[cur_label]\n",
    "                del self.columns[cur_label]\n",
    "            if promote_current_to_long_names:\n",
    "                self.set_property('long_name',new_long_names)\n",
    "            # Sort column elements to the original order as indicated by the dict values (column indices)\n",
    "            self.columns = dict(sorted(self.columns.items(), key=lambda item: item[1]))\n",
    "            self._update_col_lengths()\n",
    "        return\n",
    "\n",
    "    def get_col_names(self):\n",
    "        \"\"\"Get dict of column names  (short : long)\"\"\"\n",
    "        col_names_dict = {}\n",
    "        for col_short_name, col_idx in self.columns.items():\n",
    "            try:\n",
    "                col_names_dict[col_short_name] = self.col_properties[col_idx].long_name\n",
    "            except AttributeError:\n",
    "                col_names_dict[col_short_name] = None\n",
    "        return col_names_dict\n",
    "\n",
    "    def set_row_index(self,key_col_labels,return_index=False):\n",
    "        \"\"\"Builds the rows property based on the list of keys key_col_labels.\n",
    "\n",
    "        The resulting rows property can be accessed via selector by listing\n",
    "        key values in their hierarchical order.\n",
    "\n",
    "        Returns a DataFrame.\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        df = DataFrame({'col_a':['A','B','A','B'],'col_b':[0,0,1,1],'val':[1,2,3,4]})\n",
    "        Calling set_row_index(['col_a','col_b']) where col_a has unique values\n",
    "        'A' and 'B' and col_b has unique values 0 and 1\n",
    "        \"\"\"\n",
    "        key_cols = {} # map for indices\n",
    "        key_cols_idx = [] # list of indices' idx in data\n",
    "        value_cols = {}\n",
    "        value_cols_idx = []\n",
    "        if not isinstance(key_col_labels, list):\n",
    "            key_col_labels = [key_col_labels]\n",
    "        # List out index labels and locations\n",
    "        for col_label in key_col_labels:\n",
    "            key_cols[col_label] = self.columns[col_label]\n",
    "            key_cols_idx.append(self.columns[col_label])\n",
    "        # List out data labels and locations\n",
    "        for col_label, col_idx in self.columns.items():\n",
    "            if col_label in key_cols:\n",
    "                continue\n",
    "            else:\n",
    "                value_cols[col_label] = col_idx\n",
    "                value_cols_idx.append(col_idx)\n",
    "        # Sort data according to the provided keys\n",
    "        sorted_data=list(zip(*sorted(zip(*self.values()),key=lambda x: [x[col] for col in key_cols_idx])))\n",
    "\n",
    "        rows = NestedDict(assume_sorted=True)\n",
    "        # Create index\n",
    "        ## Iterate row at a time (i.e. iterate transposed data model)\n",
    "        for i in range(len(self._data[0])):\n",
    "            rows[[sorted_data[dim_value][i] for dim_value in key_cols_idx]] = i#[self._data[col][i] for col in range(len(self._data))]\n",
    "        # Recreate DataFrame using the results of this method\n",
    "        if not return_index:\n",
    "            new_data = {}\n",
    "            new_col_properties = {} # nested dictionary (dict for each column)\n",
    "            col_idx = 0\n",
    "            for key_col_label, old_col_idx in key_cols.items():\n",
    "                col_data = sorted_data[old_col_idx]\n",
    "                col_props = self._data[old_col_idx]._get_all_properties()\n",
    "                col_props['key'] = True\n",
    "                new_data[key_col_label] = col_data\n",
    "                new_col_properties[key_col_label] = col_props\n",
    "                col_idx += 1\n",
    "            for value_col_label, old_col_idx in value_cols.items():\n",
    "                col_data = sorted_data[old_col_idx]\n",
    "                col_props = self._data[old_col_idx]._get_all_properties()\n",
    "                col_props['key'] = False\n",
    "                new_data[value_col_label] = col_data\n",
    "                new_col_properties[value_col_label] = col_props\n",
    "                col_idx +=1\n",
    "            resulting_data_frame = DataFrame(new_data,col_properties=new_col_properties,row_index=rows,row_index_labels=key_col_labels)\n",
    "            return resulting_data_frame\n",
    "        else:\n",
    "            return rows\n",
    "\n",
    "    def aggregate(self,ignore_na=False):\n",
    "        \"\"\"Aggregates DataFrame using its keys.\n",
    "\n",
    "        Keys must be set before aggregating. Aggregation_func property\n",
    "        must also be set before aggregating.\n",
    "        This method will reshape the data by creating one record \n",
    "        for each unique key combination. Values are aggregated using \n",
    "        aggregation_func property of each column.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ignore_na : bool\n",
    "                    If set to True, will ignore any None values.\n",
    "                    If an aggregation group contains only None values\n",
    "                    for a column, that column's new value is set to None.\n",
    "                    Defaults to False.\n",
    "        \"\"\"\n",
    "        # Check for nulls\n",
    "        if not ignore_na:\n",
    "            for col_name, col_idx in self.columns.items():\n",
    "                if self._data[col_idx].any_na():\n",
    "                    raise ValueError(f\"Missing value in column {col_name}\")\n",
    "        new_data = [[] for col in self.columns.items()]\n",
    "        row_idx = 0\n",
    "        # Iterate over all unique key combinations\n",
    "        for key_values in self.rows.list_levels():\n",
    "            # Aggregate values within this key combination, one column at a time\n",
    "            for col_name, col_idx in self.columns.items():\n",
    "                # Columns marked as keys are not aggregated -- they are the keys\n",
    "                if self._data[col_idx].key:\n",
    "                    current_value = self._data[col_idx][self.rows[key_values]][0]\n",
    "                    new_data[col_idx].append(current_value)\n",
    "                else:\n",
    "                    # Apply this column's aggregation function\n",
    "                    current_values = self._data[col_idx][self.rows[key_values]]\n",
    "                    if ignore_na:\n",
    "                        current_values = [value for value in current_values if value is not None]\n",
    "                    new_value = self._data[col_idx].aggregation_func(current_values)\n",
    "                    new_data[col_idx].append(new_value)\n",
    "            self.rows[key_values] = row_idx\n",
    "            row_idx += 1\n",
    "        # Recreate dataframe one column at a time\n",
    "        for col_label, col_idx in self.columns.items():\n",
    "            new_col_data = new_data[col_idx]\n",
    "            new_col_props = self._data[col_idx]._get_all_properties()\n",
    "            self._data[col_idx] = DataColumn(new_col_data,col_properties=new_col_props)\n",
    "        return\n",
    "\n",
    "    def values(self, transpose=False, skip_col_labels=[], return_labels=False):\n",
    "        \"\"\"\n",
    "        Returns a nested list of values.\n",
    "\n",
    "        The returned nested list has shape n_cols x n_rows.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        transpose : Boolean\n",
    "                    If True, will transpose to n_rows x n_cols.\n",
    "                    Default False.\n",
    "        skip_col_labels : List of strings\n",
    "                          List of which columns to exclude from\n",
    "                          the output.  Defaults to [] (empty list).\n",
    "        return_labels : Bool\n",
    "                        Whether also to return list of labels of columns\n",
    "                        which were actually returns. Default False\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list if return_labels is False.\n",
    "        (list, labels) if return_labels is True.\n",
    "        \"\"\"\n",
    "        data_values = []\n",
    "        data_labels = []\n",
    "        for col_label, col_idx in self.columns.items():\n",
    "            if not col_label in skip_col_labels:\n",
    "                data_values.append(self._data[col_idx].data)\n",
    "                data_labels.append(col_label)\n",
    "        if transpose:\n",
    "            data_values = list(zip(*data_values))\n",
    "        if return_labels:\n",
    "            return (data_values, data_labels)\n",
    "        else:\n",
    "            return data_values\n",
    "        \n",
    "    def dict(self):\n",
    "        \"\"\"\n",
    "        Returns a dict that represents this data frame\n",
    "        \"\"\"\n",
    "        data_dict = {}\n",
    "        for col_label, col_idx in self.columns.items():\n",
    "            data_dict[col_balel] = self._data[col_idx].data\n",
    "        return data_dict\n",
    "\n",
    "    def join(self, other):\n",
    "        \"\"\"\n",
    "        Join other df to this using Left Join approach.\n",
    "    \n",
    "        Assumes that both frames have been indexed using the same key columns.\n",
    "        \"\"\"\n",
    "        # Empty list for resulting data\n",
    "        new_data = []\n",
    "        # Transpose data to avoid repetitive slicing of the same indices\n",
    "        l_full_data, l_col_labels = self.values(transpose=True, return_labels=True)\n",
    "        r_full_data, r_col_labels = other.values(transpose=True, skip_col_labels=other.row_index_labels, return_labels=True) # key cols are already in l_full_data\n",
    "        # Get indices\n",
    "        l_index = self.rows\n",
    "        r_index = other.rows\n",
    "        joined_index = NestedDict(assume_sorted=True)\n",
    "        # Helper:\n",
    "        n_left_cols = len(l_col_labels)\n",
    "        # Iterate overal all index keys and construct new data\n",
    "        for keys in l_index.list_levels():\n",
    "            l_slicer = l_index[*keys]\n",
    "            l_data = l_full_data[l_slicer]\n",
    "            l_len = len(l_data)\n",
    "            r_slicer = r_index[*keys]\n",
    "            if r_slicer == None:\n",
    "                # Create dummy r_data while keeping correct number of columns\n",
    "                r_data = [[None] for _ in r_col_labels]\n",
    "                r_len = 1\n",
    "            else:\n",
    "                r_data = r_full_data[r_slicer]\n",
    "                r_len = len(r_data)\n",
    "            joined_data = [list(it.chain(x[0],x[1])) for x in list(it.product(l_data,r_data))]\n",
    "            new_data.extend(joined_data)\n",
    "        # Update l_slicer if records had to be repeated\n",
    "        # Final preparation to construct the resulting DataFrame\n",
    "        ## Transpose new_data to cols x rows\n",
    "        new_data = list(zip(*new_data))\n",
    "        new_data_dict = {}\n",
    "        new_data_props = {}\n",
    "        ## Iterate over new columns (two iterators, one over left, one over right)\n",
    "        for i, col_label in enumerate(l_col_labels):\n",
    "            new_data_dict[col_label] = new_data[i]\n",
    "            new_data_props[col_label] = self[col_label]._get_all_properties()\n",
    "        for i, col_label in enumerate(r_col_labels):\n",
    "            new_data_dict[col_label] = new_data[i+n_left_cols]\n",
    "            new_data_props[col_label] = other[col_label]._get_all_properties()\n",
    "        return DataFrame(new_data_dict, col_properties=new_data_props)\n",
    "\n",
    "class NestedDict:\n",
    "    def __init__(self,assume_sorted:bool):\n",
    "        if not isinstance(assume_sorted,bool):\n",
    "            raise ValueError(\"assume_sorted must be provided as a bool\")\n",
    "        self.assume_sorted = assume_sorted\n",
    "        self.data = defaultdict(lambda: None)\n",
    "        return\n",
    "\n",
    "    def __setitem__(self, keys, value):\n",
    "        \"\"\"Build nested dictionary from keys list and value object\n",
    "\n",
    "        Each next key in keys will produce another nested dict key,\n",
    "        with the last key's value being assigned the value\n",
    "        as an element of a list.\n",
    "        If the exact specified keys already exist, the value will\n",
    "        be appended to the list value of the last key.\n",
    "        \"\"\"\n",
    "        if len(keys)>1:\n",
    "            if not keys[0] in self.data:\n",
    "                self.data[keys[0]] = NestedDict(self.assume_sorted)\n",
    "            self.data[keys[0]][keys[1:]] = value\n",
    "        else:\n",
    "            if not self.assume_sorted:\n",
    "                # Collect list of indices\n",
    "                if isinstance(self.data[keys[0]] ,list):\n",
    "                    self.data[keys[0]].append(value)\n",
    "                else:\n",
    "                    self.data[keys[0]] = [value]\n",
    "            else:\n",
    "                # Build slicer objects\n",
    "                if isinstance(self.data[keys[0]] ,slice):\n",
    "                    self.data[keys[0]] = slice(self.data[keys[0]].start,value+1) # Replaces existing slice with new one by keeping the same start but modifying the end. This works because data is sorted\n",
    "                else:\n",
    "                    self.data[keys[0]] = slice(value,value+1)\n",
    "        return\n",
    "\n",
    "    def __getitem__(self, keys):\n",
    "        if len(keys)>1:\n",
    "            return self.data[keys[0]][keys[1:]]\n",
    "        else:\n",
    "            return self.data[keys[0]]\n",
    "\n",
    "    def labels(self):\n",
    "        return list(self.data.keys())\n",
    "\n",
    "    def list_levels(self, trail=[]):\n",
    "        \"\"\"Generate list of allkey combinations.\n",
    "        \n",
    "        All, i.e. all levels', keys are returned as a nested list.\n",
    "        Each inner list contains the keys for each key column.\n",
    "        \"\"\"\n",
    "        resulting_levels=[]\n",
    "        if isinstance(self.data[list(self.data.keys())[0]],NestedDict):\n",
    "            for key, nested_dict in self.data.items():\n",
    "                this_result = nested_dict.list_levels(trail=trail + [key])\n",
    "                resulting_levels.extend(this_result)\n",
    "        else:\n",
    "            resulting_levels = [trail + [key] for key in self.data.keys()]\n",
    "        return resulting_levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8b8aa8-b233-438b-8af9-1ee94c6fb162",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Dummy tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "56c61b02-b31f-40ff-947a-9943de499bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([1], [9]), ([1], [8]), ([2], [9]), ([2], [8]), ([3], [9]), ([3], [8])]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(it.product([[1],[2],[3]],[[9],[8]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68446296-3cd4-40d6-9819-bcbfa24eec5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1d71f6c7-f515-44a2-8d7d-e62d8140be1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = DataFrame({'col_b':['A','A','B','C'],'col_val' : [45,46,22,91]},dtypes={'col_b':str,'col_val':float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "adf62623-eb04-4153-bc11-3f7330dced64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.set_row_index('col_b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "66909d2d-40d1-42ab-b31a-0a053d7c0f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | col_b  | col_val  | \n",
      "  | \u001b[35m   str\u001b[0m | \u001b[32m     num\u001b[0m | \n",
      "i |      *\u001b[31m\u001b[0m |         \u001b[31m\u001b[0m | \n",
      "-----------------------\n",
      "0 |      A |     45.0 | \n",
      "1 |      A |     46.0 | \n",
      "2 |      B |     22.0 | \n",
      "3 |      C |     91.0 | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame with 2 columns and 4 rows"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "bf96957c-6196-4346-bdf7-847dacc5935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = DataFrame({'col_b':['A','A','B','B','B','D'],'test' : [1,2,1,6,7,8]},dtypes={'col_b':str,'test':int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ffc594b3-3a59-416e-9222-512f93a7f982",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_2.set_row_index('col_b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c3cb9684-1dcc-43ef-bbbb-8d3568579ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | col_b  | test  | \n",
      "  | \u001b[35m   str\u001b[0m | \u001b[32m  num\u001b[0m | \n",
      "i |      *\u001b[31m\u001b[0m |      \u001b[31m\u001b[0m | \n",
      "--------------------\n",
      "0 |      A |     1 | \n",
      "1 |      A |     2 | \n",
      "2 |      B |     1 | \n",
      "3 |      B |     6 | \n",
      "4 |      B |     7 | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame with 2 columns and 6 rows"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "523f94a4-044d-4ee1-a8ee-bc32adb15428",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A']\n",
      "[('A', 45.0), ('A', 46.0)]\n",
      "[(1,), (2,)]\n",
      "\n",
      "['B']\n",
      "[('B', 22.0)]\n",
      "[(1,), (6,), (7,)]\n",
      "\n",
      "['C']\n",
      "[('C', 91.0)]\n",
      "[[None]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df = df_1.join(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0d71c225-d980-4adf-89c4-b7f61436cfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | col_b  | col_val  | test  | \n",
      "   | \u001b[35m   str\u001b[0m | \u001b[32m     num\u001b[0m | \u001b[32m  num\u001b[0m | \n",
      " i |      *\u001b[31m\u001b[0m |         \u001b[31m\u001b[0m |    \u001b[31m !\u001b[0m | \n",
      "--------------------------------\n",
      " 0 |      A |     45.0 |     1 | \n",
      " 1 |      A |     45.0 |     2 | \n",
      " 2 |      A |     46.0 |     1 | \n",
      " 3 |      A |     46.0 |     2 | \n",
      " 4 |      B |     22.0 |     1 | \n",
      " 5 |      B |     22.0 |     6 | \n",
      " 6 |      B |     22.0 |     7 | \n",
      " 7 |      C |     91.0 | \u001b[31m   --\u001b[0m | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DataFrame with 3 columns and 8 rows'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.show(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "caacd79c-cc87-404d-9d25-3b134d1559a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 45.0, 'A', 46.0]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(it.chain.from_iterable([('A', 45.0), ('A', 46.0)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20084fb4-04b9-4cd8-8ddd-0b8743c53d55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "efab8580-7ef0-4eba-b342-9792326e5f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['A', 45.0, 1], ['A', 45.0, 2], ['A', 46.0, 1], ['A', 46.0, 2]]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(it.chain(x[0],x[1])) for x in list(it.product([('A', 45.0), ('A', 46.0)],([(1,),(2,)])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "106cf5f9-c9c3-48b7-9303-51f7f2b84965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 1),\n",
       " ('A', 2),\n",
       " (45.0, 1),\n",
       " (45.0, 2),\n",
       " ('A', 1),\n",
       " ('A', 2),\n",
       " (46.0, 1),\n",
       " (46.0, 2)]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(it.product(it.chain.from_iterable([('A', 45.0), ('A', 46.0)]),it.chain.from_iterable(([(1,),(2,)]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ef00a6b0-a73d-4afd-b706-0b36cd57d8fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('A', 45.0),\n",
       "  ('A', 45.0),\n",
       "  ('A', 46.0),\n",
       "  ('A', 46.0),\n",
       "  ('A', 45.0),\n",
       "  ('A', 45.0),\n",
       "  ('A', 46.0),\n",
       "  ('A', 46.0)),\n",
       " (1, 2, 1, 2, 1, 2, 1, 2)]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(*[(('A', 45.0), 1),\n",
    " (('A', 45.0), 2),\n",
    " (('A', 46.0), 1),\n",
    " (('A', 46.0), 2),\n",
    " (('A', 45.0), 1),\n",
    " (('A', 45.0), 2),\n",
    " (('A', 46.0), 1),\n",
    " (('A', 46.0), 2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74da1c5c-6852-44dd-9e33-4e11b3f18b00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd25e244-ceac-43c9-9706-9a8c9089ae88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "75b4f434-1cfa-4de9-993e-21b8adc897f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | col_a  | col_b  | col_num  | long_text_col  | \n",
      "    | \u001b[31m   UNK\u001b[0m | \u001b[31m   UNK\u001b[0m | \u001b[31m     UNK\u001b[0m | \u001b[31m           UNK\u001b[0m | \n",
      "  i |       \u001b[31m\u001b[0m |     \u001b[31m !\u001b[0m |       \u001b[31m !\u001b[0m |               \u001b[31m\u001b[0m | \n",
      "---------------------------------------------------\n",
      "  0 |      a |      A |       11 | this is long t | \n",
      "  1 |      b |      B |       21 | this is long t | \n",
      "  2 |      c |      C |       13 | this is long t | \n",
      "  3 |      d |      D |       23 | this is long t | \n",
      "  4 |      e |      E |        8 | this is long t | \n",
      "  5 |      f |      F |       12 | this is long t | \n",
      "  6 |      a |      A |       11 | this is long t | \n",
      "  7 |      b |      B |        2 | this is  thext | \n",
      "  8 |      c |      C |        2 | this is long t | \n",
      "  9 |      d |      D |       82 | this is long t | \n",
      " 10 |      e |      A |       11 | this is long t | \n",
      " 11 |      f |      B |       21 | this is long t | \n",
      " 12 |      o |      C | \u001b[31m      --\u001b[0m | this is long t | \n",
      " 13 |      p |      D |       23 | this is long t | \n",
      " 14 |      q |      E |       8  | this is long   | \n",
      " 15 |      r |      F |       12 | this is long t | \n",
      " 16 |      e |      A |       11 | this is long t | \n",
      " 17 |      f |      B |        2 | this is long t | \n",
      " 18 |      o |      C |        2 | this is long t | \n",
      " 19 |      p |      D |       82 | this is long t | \n",
      " 20 |      q | \u001b[31m    --\u001b[0m |       13 | this is long t | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DataFrame with 4 columns and 21 rows'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = DataFrame()\n",
    "df.read_csv(\"input_test.csv\")\n",
    "df.show(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "180f764a-5e82-454a-b6ae-8aca6e16bda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame()\n",
    "df.read_csv(\"input_test.csv\")\n",
    "df['col_b'] = df['col_b'].fillna('Missing')\n",
    "df = df.set_row_index('col_b')\n",
    "\n",
    "df_right = DataFrame({'col_b' : ['A','B','C','A','A','X','X','W'], 'r1' : [1,2,3,4,5,6,7,7]})\n",
    "df_right = df_right.set_row_index(['col_b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4186f941-091c-4917-9bcc-b51893e47557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |  col_b   | col_a  | col_num  | long_text_col  |  r1   | \n",
      "    | \u001b[31m     UNK\u001b[0m | \u001b[31m   UNK\u001b[0m | \u001b[31m     UNK\u001b[0m | \u001b[31m           UNK\u001b[0m | \u001b[31m  UNK\u001b[0m | \n",
      "  i |        *\u001b[31m\u001b[0m |       \u001b[31m\u001b[0m |       \u001b[31m !\u001b[0m |               \u001b[31m\u001b[0m |    \u001b[31m !\u001b[0m | \n",
      "-------------------------------------------------------------\n",
      "  0 |        A |      a |       11 | this is long t |     1 | \n",
      "  1 |        A |      a |       11 | this is long t |     4 | \n",
      "  2 |        A |      a |       11 | this is long t |     5 | \n",
      "  3 |        A |      a |       11 | this is long t |     1 | \n",
      "  4 |        A |      a |       11 | this is long t |     4 | \n",
      "  5 |        A |      a |       11 | this is long t |     5 | \n",
      "  6 |        A |      e |       11 | this is long t |     1 | \n",
      "  7 |        A |      e |       11 | this is long t |     4 | \n",
      "  8 |        A |      e |       11 | this is long t |     5 | \n",
      "  9 |        A |      e |       11 | this is long t |     1 | \n",
      " 10 |        A |      e |       11 | this is long t |     4 | \n",
      " 11 |        A |      e |       11 | this is long t |     5 | \n",
      " 12 |        B |      b |       21 | this is long t |     2 | \n",
      " 13 |        B |      b |        2 | this is  thext |     2 | \n",
      " 14 |        B |      f |       21 | this is long t |     2 | \n",
      " 15 |        B |      f |        2 | this is long t |     2 | \n",
      " 16 |        C |      c |       13 | this is long t |     3 | \n",
      " 17 |        C |      c |        2 | this is long t |     3 | \n",
      " 18 |        C |      o | \u001b[31m      --\u001b[0m | this is long t |     3 | \n",
      " 19 |        C |      o |        2 | this is long t |     3 | \n",
      " 20 |        D |      d |       23 | this is long t | \u001b[31m   --\u001b[0m | \n",
      " 21 |        D |      d |       82 | this is long t | \u001b[31m   --\u001b[0m | \n",
      " 22 |        D |      p |       23 | this is long t | \u001b[31m   --\u001b[0m | \n",
      " 23 |        D |      p |       82 | this is long t | \u001b[31m   --\u001b[0m | \n",
      " 24 |        E |      e |        8 | this is long t | \u001b[31m   --\u001b[0m | \n",
      " 25 |        E |      q |       8  | this is long   | \u001b[31m   --\u001b[0m | \n",
      " 26 |        F |      f |       12 | this is long t | \u001b[31m   --\u001b[0m | \n",
      " 27 |        F |      r |       12 | this is long t | \u001b[31m   --\u001b[0m | \n",
      " 28 |  Missing |      q |       13 | this is long t | \u001b[31m   --\u001b[0m | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DataFrame with 5 columns and 29 rows'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.join(df_right).show(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d78f59fd-96b8-4fac-b41a-77fa379c9191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |  col_b   | col_a  | col_num  | long_text_col  | \n",
      "    | \u001b[31m     UNK\u001b[0m | \u001b[31m   UNK\u001b[0m | \u001b[31m     UNK\u001b[0m | \u001b[31m           UNK\u001b[0m | \n",
      "  i |        *\u001b[31m\u001b[0m |       \u001b[31m\u001b[0m |       \u001b[31m !\u001b[0m |               \u001b[31m\u001b[0m | \n",
      "-----------------------------------------------------\n",
      "  0 |        A |      a |       11 | this is long t | \n",
      "  1 |        A |      a |       11 | this is long t | \n",
      "  2 |        A |      e |       11 | this is long t | \n",
      "  3 |        A |      e |       11 | this is long t | \n",
      "  4 |        B |      b |       21 | this is long t | \n",
      "  5 |        B |      b |        2 | this is  thext | \n",
      "  6 |        B |      f |       21 | this is long t | \n",
      "  7 |        B |      f |        2 | this is long t | \n",
      "  8 |        C |      c |       13 | this is long t | \n",
      "  9 |        C |      c |        2 | this is long t | \n",
      " 10 |        C |      o | \u001b[31m      --\u001b[0m | this is long t | \n",
      " 11 |        C |      o |        2 | this is long t | \n",
      " 12 |        D |      d |       23 | this is long t | \n",
      " 13 |        D |      d |       82 | this is long t | \n",
      " 14 |        D |      p |       23 | this is long t | \n",
      " 15 |        D |      p |       82 | this is long t | \n",
      " 16 |        E |      e |        8 | this is long t | \n",
      " 17 |        E |      q |       8  | this is long   | \n",
      " 18 |        F |      f |       12 | this is long t | \n",
      " 19 |        F |      r |       12 | this is long t | \n",
      " 20 |  Missing |      q |       13 | this is long t | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DataFrame with 4 columns and 21 rows'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.show(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8c3242-9738-4945-abd2-cdcef7a1a33e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59addde4-c8d3-4d97-9268-20cfeaa292ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "05644141-f22b-421f-92c6-c68ef7f4059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ff1bcc41-a8af-4444-a9cc-903ab77a979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.read_csv(\"input_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a6f59a6-6c87-4013-9d34-d47082509923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | col_a  | col_b  | col_num  | long_text_col  | \n",
      "  | \u001b[31m   UNK\u001b[0m | \u001b[31m   UNK\u001b[0m | \u001b[31m     UNK\u001b[0m | \u001b[31m           UNK\u001b[0m | \n",
      "i |       \u001b[31m\u001b[0m |     \u001b[31m !\u001b[0m |       \u001b[31m !\u001b[0m |               \u001b[31m\u001b[0m | \n",
      "-------------------------------------------------\n",
      "0 |      a |      A |       11 | this is long t | \n",
      "1 |      b |      B |       21 | this is long t | \n",
      "2 |      c |      C |       13 | this is long t | \n",
      "3 |      d |      D |       23 | this is long t | \n",
      "4 |      e |      E |        8 | this is long t | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame with 4 columns and 21 rows"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "abd57b9e-dbf2-4c25-80c9-40f977348125",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_property('dtype',{'col_a':str,'col_b':str,'col_num':int,'long_text_col':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ba8efefd-088c-4006-b37c-c83100a48737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | col_a  | col_b  | col_num  | long_text_col  | \n",
      "  | \u001b[35m   str\u001b[0m | \u001b[35m   str\u001b[0m | \u001b[32m     num\u001b[0m | \u001b[35m           str\u001b[0m | \n",
      "i |       \u001b[31m\u001b[0m |     \u001b[31m !\u001b[0m |       \u001b[31m !\u001b[0m |               \u001b[31m\u001b[0m | \n",
      "-------------------------------------------------\n",
      "0 |      a |      A |       11 | this is long t | \n",
      "1 |      b |      B |       21 | this is long t | \n",
      "2 |      c |      C |       13 | this is long t | \n",
      "3 |      d |      D |       23 | this is long t | \n",
      "4 |      e |      E |        8 | this is long t | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame with 4 columns and 21 rows"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "96194d02-097f-4206-957a-5ebf25ddec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_short_col_names({'long_text_col' : 'col_char'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b5e5446a-10a5-4cec-8e35-c6708c534e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | col_a  | col_b  | col_num  |  col_char  | \n",
      "  | \u001b[35m   str\u001b[0m | \u001b[35m   str\u001b[0m | \u001b[32m     num\u001b[0m | \u001b[35m       str\u001b[0m | \n",
      "i |       \u001b[31m\u001b[0m |     \u001b[31m !\u001b[0m |       \u001b[31m !\u001b[0m |           \u001b[31m\u001b[0m | \n",
      "---------------------------------------------\n",
      "0 |      a |      A |       11 | this is lo | \n",
      "1 |      b |      B |       21 | this is lo | \n",
      "2 |      c |      C |       13 | this is lo | \n",
      "3 |      d |      D |       23 | this is lo | \n",
      "4 |      e |      E |        8 | this is lo | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame with 4 columns and 21 rows"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7264b4f9-f5dc-4cf2-92b0-a24c4f864f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_property('aggregation_func',{'col_num' : statistics.mean, 'col_char' : len})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ab409188-dad3-40f7-a105-110d5d52e4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | col_a  | col_b  | col_num  |  col_char  | \n",
      "  | \u001b[35m   str\u001b[0m | \u001b[35m   str\u001b[0m | \u001b[32m     num\u001b[0m | \u001b[35m       str\u001b[0m | \n",
      "i |       \u001b[31m\u001b[0m |     \u001b[31m !\u001b[0m |   mean\u001b[31m !\u001b[0m |        len\u001b[31m\u001b[0m | \n",
      "---------------------------------------------\n",
      "0 |      a |      A |       11 | this is lo | \n",
      "1 |      b |      B |       21 | this is lo | \n",
      "2 |      c |      C |       13 | this is lo | \n",
      "3 |      d |      D |       23 | this is lo | \n",
      "4 |      e |      E |        8 | this is lo | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame with 4 columns and 21 rows"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1fa919e8-3408-433a-974e-a701f9945aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | col_a  | col_b  | col_num  |  col_char  | \n",
      "  | \u001b[35m   str\u001b[0m | \u001b[35m   str\u001b[0m | \u001b[32m     num\u001b[0m | \u001b[35m       str\u001b[0m | \n",
      "i |       \u001b[31m\u001b[0m |     \u001b[31m !\u001b[0m |   mean\u001b[31m !\u001b[0m |        len\u001b[31m\u001b[0m | \n",
      "---------------------------------------------\n",
      "0 |      a |      A |       11 | this is lo | \n",
      "1 |      b |      B |       21 | this is lo | \n",
      "2 |      c |      C |       13 | this is lo | \n",
      "3 |      d |      D |       23 | this is lo | \n",
      "4 |      e |      E |        8 | this is lo | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame with 4 columns and 21 rows"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e35b0617-9eaf-4ee9-be8e-020339ae2263",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col_b'] = df['col_b'].fillna('Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "37fbcd68-6782-4f93-b3ca-e2c027c89053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | col_a  |  col_b   | col_num  |  col_char  | \n",
      "  | \u001b[35m   str\u001b[0m | \u001b[35m     str\u001b[0m | \u001b[32m     num\u001b[0m | \u001b[35m       str\u001b[0m | \n",
      "i |       \u001b[31m\u001b[0m |         \u001b[31m\u001b[0m |   mean\u001b[31m !\u001b[0m |        len\u001b[31m\u001b[0m | \n",
      "-----------------------------------------------\n",
      "0 |      a |        A |       11 | this is lo | \n",
      "1 |      b |        B |       21 | this is lo | \n",
      "2 |      c |        C |       13 | this is lo | \n",
      "3 |      d |        D |       23 | this is lo | \n",
      "4 |      e |        E |        8 | this is lo | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame with 4 columns and 21 rows"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2f25529e-c623-4575-938f-a2f64363a993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | col_a  |  col_b   | col_num  |  col_char  | \n",
      "    | \u001b[35m   str\u001b[0m | \u001b[35m     str\u001b[0m | \u001b[32m     num\u001b[0m | \u001b[35m       str\u001b[0m | \n",
      "  i |       \u001b[31m\u001b[0m |         \u001b[31m\u001b[0m |   mean\u001b[31m !\u001b[0m |        len\u001b[31m\u001b[0m | \n",
      "-------------------------------------------------\n",
      "  0 |      a |        A |       11 | this is lo | \n",
      "  1 |      b |        B |       21 | this is lo | \n",
      "  2 |      c |        C |       13 | this is lo | \n",
      "  3 |      d |        D |       23 | this is lo | \n",
      "  4 |      e |        E |        8 | this is lo | \n",
      "  5 |      f |        F |       12 | this is lo | \n",
      "  6 |      a |        A |       11 | this is lo | \n",
      "  7 |      b |        B |        2 | this is  t | \n",
      "  8 |      c |        C |        2 | this is lo | \n",
      "  9 |      d |        D |       82 | this is lo | \n",
      " 10 |      e |        A |       11 | this is lo | \n",
      " 11 |      f |        B |       21 | this is lo | \n",
      " 12 |      o |        C | \u001b[31m      --\u001b[0m | this is lo | \n",
      " 13 |      p |        D |       23 | this is lo | \n",
      " 14 |      q |        E |        8 | this is lo | \n",
      " 15 |      r |        F |       12 | this is lo | \n",
      " 16 |      e |        A |       11 | this is lo | \n",
      " 17 |      f |        B |        2 | this is lo | \n",
      " 18 |      o |        C |        2 | this is lo | \n",
      " 19 |      p |        D |       82 | this is lo | \n",
      " 20 |      q |  Missing |       13 | this is lo | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DataFrame with 4 columns and 21 rows'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.show(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aa7ca3cc-774b-4726-8d69-e9fe897d6f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.set_row_index(['col_b','col_a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7121daec-2000-4a78-863f-e917a2d2d9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |  col_b   | col_a  | col_num  |  col_char  | \n",
      "  | \u001b[35m     str\u001b[0m | \u001b[35m   str\u001b[0m | \u001b[32m     num\u001b[0m | \u001b[35m       str\u001b[0m | \n",
      "i |        *\u001b[31m\u001b[0m |      *\u001b[31m\u001b[0m |   mean\u001b[31m !\u001b[0m |        len\u001b[31m\u001b[0m | \n",
      "-----------------------------------------------\n",
      "0 |        A |      a |       11 | this is lo | \n",
      "1 |        A |      a |       11 | this is lo | \n",
      "2 |        A |      e |       11 | this is lo | \n",
      "3 |        A |      e |       11 | this is lo | \n",
      "4 |        B |      b |       21 | this is lo | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame with 4 columns and 21 rows"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e2405a64-a9fd-4946-b162-7dd757e09761",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing value in column col_num",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m df\u001b[38;5;241m.\u001b[39mset_property(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maggregation_func\u001b[39m\u001b[38;5;124m'\u001b[39m,{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcol_num\u001b[39m\u001b[38;5;124m'\u001b[39m : statistics\u001b[38;5;241m.\u001b[39mmean, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcol_char\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;28mlen\u001b[39m}) \u001b[38;5;66;03m################ why\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#df['col_num'] = df['col_num'].fillna(0)###############################3\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 986\u001b[0m, in \u001b[0;36mDataFrame.aggregate\u001b[1;34m(self, ignore_na)\u001b[0m\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col_name, col_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[col_idx]\u001b[38;5;241m.\u001b[39many_na():\n\u001b[1;32m--> 986\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing value in column \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    987\u001b[0m new_data \u001b[38;5;241m=\u001b[39m [[] \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[0;32m    988\u001b[0m row_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Missing value in column col_num"
     ]
    }
   ],
   "source": [
    "df.set_property('aggregation_func',{'col_num' : statistics.mean, 'col_char' : len}) ################ why\n",
    "#df['col_num'] = df['col_num'].fillna(0)###############################3\n",
    "df.aggregate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "85645368-f8ca-45c9-b660-7612d5b2fe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.aggregate(ignore_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5bda69d7-1afc-462c-a633-ce77015f839e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |  col_b   | col_a  | col_num  |  col_char  | \n",
      "    | \u001b[35m     str\u001b[0m | \u001b[35m   str\u001b[0m | \u001b[32m     num\u001b[0m | \u001b[35m       str\u001b[0m | \n",
      "  i |        *\u001b[31m\u001b[0m |      *\u001b[31m\u001b[0m |     mean\u001b[31m\u001b[0m |        len\u001b[31m\u001b[0m | \n",
      "-------------------------------------------------\n",
      "  0 |        A |      a |       11 |          2 | \n",
      "  1 |        A |      e |       11 |          2 | \n",
      "  2 |        B |      b |     11.5 |          2 | \n",
      "  3 |        B |      f |     11.5 |          2 | \n",
      "  4 |        C |      c |      7.5 |          2 | \n",
      "  5 |        C |      o |        2 |          2 | \n",
      "  6 |        D |      d |     52.5 |          2 | \n",
      "  7 |        D |      p |     52.5 |          2 | \n",
      "  8 |        E |      e |        8 |          1 | \n",
      "  9 |        E |      q |        8 |          1 | \n",
      " 10 |        F |      f |       12 |          1 | \n",
      " 11 |        F |      r |       12 |          1 | \n",
      " 12 |  Missing |      q |       13 |          1 | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DataFrame with 4 columns and 13 rows'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.show(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f742c4f3-f05c-4c7f-b574-79fe557d2817",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_right = DataFrame({'col_b' : ['A','B','C','A','A','X','X','W'], 'r1' : [1,2,3,4,5,6,7,7]})\n",
    "df_right = df_right.set_row_index(['col_b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5fd92a6d-9390-4f46-8bea-98a3e84fb5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | col_b  |  r1   | \n",
      "  | \u001b[31m   UNK\u001b[0m | \u001b[31m  UNK\u001b[0m | \n",
      "i |      *\u001b[31m\u001b[0m |      \u001b[31m\u001b[0m | \n",
      "--------------------\n",
      "0 |      A |     1 | \n",
      "1 |      A |     4 | \n",
      "2 |      A |     5 | \n",
      "3 |      B |     2 | \n",
      "4 |      C |     3 | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame with 2 columns and 8 rows"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e6a23926-1c82-4d59-b849-3795d667e8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_row_index('col_b')\n",
    "joined_df = df.join(df_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6c2ec6c2-45ae-4283-a612-212f54c7428e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |  col_b   | col_a  | col_num  | col_char  | \n",
      "    | \u001b[35m     str\u001b[0m | \u001b[35m   str\u001b[0m | \u001b[32m     num\u001b[0m | \u001b[35m      str\u001b[0m | \n",
      "  i |        *\u001b[31m\u001b[0m |       \u001b[31m\u001b[0m |     mean\u001b[31m\u001b[0m |       len\u001b[31m\u001b[0m | \n",
      "------------------------------------------------\n",
      "  0 |        A |      a |       11 |         2 | \n",
      "  1 |        A |      e |       11 |         2 | \n",
      "  2 |        B |      b |     11.5 |         2 | \n",
      "  3 |        B |      f |     11.5 |         2 | \n",
      "  4 |        C |      c |      7.5 |         2 | \n",
      "  5 |        C |      o |        2 |         2 | \n",
      "  6 |        D |      d |     52.5 |         2 | \n",
      "  7 |        D |      p |     52.5 |         2 | \n",
      "  8 |        E |      e |        8 |         1 | \n",
      "  9 |        E |      q |        8 |         1 | \n",
      " 10 |        F |      f |       12 |         1 | \n",
      " 11 |        F |      r |       12 |         1 | \n",
      " 12 |  Missing |      q |       13 |         1 | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DataFrame with 4 columns and 13 rows'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.show(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8493b252-45b7-4d79-9d93-ab7e18645a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |  col_b   | col_a  | col_num  | col_char  |  r1   | \n",
      "    | \u001b[35m     str\u001b[0m | \u001b[35m   str\u001b[0m | \u001b[32m     num\u001b[0m | \u001b[35m      str\u001b[0m | \u001b[31m  UNK\u001b[0m | \n",
      "  i |        *\u001b[31m\u001b[0m |       \u001b[31m\u001b[0m |     mean\u001b[31m\u001b[0m |       len\u001b[31m\u001b[0m |    \u001b[31m !\u001b[0m | \n",
      "--------------------------------------------------------\n",
      "  0 |        A |      a |       11 |         2 |     1 | \n",
      "  1 |        A |      e |       11 |         2 |     4 | \n",
      "  2 |        A |      a |       11 |         2 |     5 | \n",
      "  3 |        B |      b |     11.5 |         2 |     2 | \n",
      "  4 |        C |      c |      7.5 |         2 |     3 | \n",
      "  5 |        D |      d |     52.5 |         2 | \u001b[31m   --\u001b[0m | \n",
      "  6 |        E |      e |        8 |         1 | \u001b[31m   --\u001b[0m | \n",
      "  7 |        F |      f |       12 |         1 | \u001b[31m   --\u001b[0m | \n",
      "  8 |  Missing |      q |       13 |         1 | \u001b[31m   --\u001b[0m | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DataFrame with 5 columns and 9 rows'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.show(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "08456fa0-151a-4541-886d-a736c7278df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | col_b  |  r1   | \n",
      "  | \u001b[31m   UNK\u001b[0m | \u001b[31m  UNK\u001b[0m | \n",
      "i |      *\u001b[31m\u001b[0m |      \u001b[31m\u001b[0m | \n",
      "--------------------\n",
      "0 |      A |     1 | \n",
      "1 |      A |     4 | \n",
      "2 |      A |     5 | \n",
      "3 |      B |     2 | \n",
      "4 |      C |     3 | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame with 2 columns and 8 rows"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4a1abd-acae-4100-8103-e11eb669437b",
   "metadata": {},
   "source": [
    "### Demo data tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78076f66-3a14-4b76-8547-f10bd0b3859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame()\n",
    "df.read_csv(\"../../000_local_data_raw/20240529df_test_restricted/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e082393b-1b74-4671-bea1-1cd5849973a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_short_col_names({'ï»¿extract_date' : 'extract_date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c2d02c8-10a8-492d-8a6a-5f3f7cf98e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['extract_date', 'person_id', 'pay_plan', 'grade']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83992dd0-a33f-456f-b300-d2854b09238b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('05/12/2024 00:00:00',\n",
       "  '05/12/2024 00:00:00',\n",
       "  '05/12/2024 00:00:00',\n",
       "  '05/12/2024 00:00:00',\n",
       "  '05/12/2024 00:00:00',\n",
       "  '05/12/2024 00:00:00',\n",
       "  '05/12/2024 00:00:00',\n",
       "  '05/12/2024 00:00:00',\n",
       "  '05/12/2024 00:00:00',\n",
       "  '05/12/2024 00:00:00'),\n",
       " ('135,604',\n",
       "  '8,721',\n",
       "  '8,721',\n",
       "  '8,721',\n",
       "  '8,721',\n",
       "  '8,721',\n",
       "  '282,263',\n",
       "  '282,263',\n",
       "  '205,687',\n",
       "  '47,840'),\n",
       " ('GS', 'GS', 'GS', 'GS', 'GS', 'GS', 'GS', 'GS', 'GS', 'GS'),\n",
       " ('11', '12', '12', '12', '12', '12', '11', '11', '14', '12')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:10,].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f68cb0a0-f27f-4444-9972-3bfbb07edaf1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannon cast 135,604 to <class 'int'>: invalid literal for int() with base 10: '135,604'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 418\u001b[0m, in \u001b[0;36mDataColumn.as_type\u001b[1;34m(self, new_type)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 418\u001b[0m     casted_val \u001b[38;5;241m=\u001b[39m \u001b[43mnew_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    419\u001b[0m casted_values\u001b[38;5;241m.\u001b[39mappend(casted_val)\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '135,604'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_property\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mperson_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 870\u001b[0m, in \u001b[0;36mDataFrame.set_property\u001b[1;34m(self, property_type, new_properties)\u001b[0m\n\u001b[0;32m    868\u001b[0m     \u001b[38;5;66;03m# In addition, if dtype was changed, cast the column into the new dtype\u001b[39;00m\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m property_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 870\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[col_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprop_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 421\u001b[0m, in \u001b[0;36mDataColumn.as_type\u001b[1;34m(self, new_type)\u001b[0m\n\u001b[0;32m    419\u001b[0m         casted_values\u001b[38;5;241m.\u001b[39mappend(casted_val)\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 421\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannon cast \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    422\u001b[0m col_props \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_all_properties()\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataColumn(casted_values,col_properties\u001b[38;5;241m=\u001b[39mcol_props)\n",
      "\u001b[1;31mValueError\u001b[0m: Cannon cast 135,604 to <class 'int'>: invalid literal for int() with base 10: '135,604'"
     ]
    }
   ],
   "source": [
    "df.set_property('dtype',{'person_id':int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035f6d5c-7234-4458-86f3-12f0785764bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_property('aggregation_func',{'person_id':'nunique','grade':'mean'})\n",
    "df.set_property('dtype',{'person_id':str,'grade':int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "051918d3-28bf-4e8e-a199-152919a89bec",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannon cast 135,604 to <class 'int'>: invalid literal for int() with base 10: '135,604'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 418\u001b[0m, in \u001b[0;36mDataColumn.as_type\u001b[1;34m(self, new_type)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 418\u001b[0m     casted_val \u001b[38;5;241m=\u001b[39m \u001b[43mnew_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    419\u001b[0m casted_values\u001b[38;5;241m.\u001b[39mappend(casted_val)\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '135,604'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[115], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_property\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mperson_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[99], line 870\u001b[0m, in \u001b[0;36mDataFrame.set_property\u001b[1;34m(self, property_type, new_properties)\u001b[0m\n\u001b[0;32m    868\u001b[0m     \u001b[38;5;66;03m# In addition, if dtype was changed, cast the column into the new dtype\u001b[39;00m\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m property_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 870\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[col_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprop_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[99], line 421\u001b[0m, in \u001b[0;36mDataColumn.as_type\u001b[1;34m(self, new_type)\u001b[0m\n\u001b[0;32m    419\u001b[0m         casted_values\u001b[38;5;241m.\u001b[39mappend(casted_val)\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 421\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannon cast \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    422\u001b[0m col_props \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_all_properties()\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataColumn(casted_values,col_properties\u001b[38;5;241m=\u001b[39mcol_props)\n",
      "\u001b[1;31mValueError\u001b[0m: Cannon cast 135,604 to <class 'int'>: invalid literal for int() with base 10: '135,604'"
     ]
    }
   ],
   "source": [
    "df.set_property('dtype',{'person_id':int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "df7751cb-53a3-4004-a2c9-670730ec8910",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_row_index(['extract_date','pay_plan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5a241a01-c735-48a2-980e-f41441d16e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | extract_date  | pay_plan  | person_id  | grade  | \n",
      "  | \u001b[31m          UNK\u001b[0m | \u001b[31m      UNK\u001b[0m | \u001b[35m       str\u001b[0m | \u001b[32m   num\u001b[0m | \n",
      "i |             *\u001b[31m\u001b[0m |         *\u001b[31m\u001b[0m |    nunique\u001b[31m\u001b[0m |   mean\u001b[31m\u001b[0m | \n",
      "-----------------------------------------------------\n",
      "0 | 01/01/2024 00 |        EE |    428,313 |      0 | \n",
      "1 | 01/01/2024 00 |        ES |      5,055 |      0 | \n",
      "2 | 01/01/2024 00 |        ES |      5,055 |      0 | \n",
      "3 | 01/01/2024 00 |        ES |    232,800 |      0 | \n",
      "4 | 01/01/2024 00 |        ES |     13,978 |      0 | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DataFrame with 4 columns and 355660 rows'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "880c463c-3afb-46ee-9c56-0155dcd86c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.aggregate(ignore_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a0ba9bb7-3b43-494f-9900-3b1ee9252dca",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannon cast <function nunique.<locals>.<lambda> at 0x0000024F5A0BEDE0> to <class 'int'>: int() argument must be a string, a bytes-like object or a real number, not 'function'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 418\u001b[0m, in \u001b[0;36mDataColumn.as_type\u001b[1;34m(self, new_type)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 418\u001b[0m     casted_val \u001b[38;5;241m=\u001b[39m \u001b[43mnew_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    419\u001b[0m casted_values\u001b[38;5;241m.\u001b[39mappend(casted_val)\n",
      "\u001b[1;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'function'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_property\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mperson_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[99], line 870\u001b[0m, in \u001b[0;36mDataFrame.set_property\u001b[1;34m(self, property_type, new_properties)\u001b[0m\n\u001b[0;32m    868\u001b[0m     \u001b[38;5;66;03m# In addition, if dtype was changed, cast the column into the new dtype\u001b[39;00m\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m property_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 870\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[col_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprop_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[99], line 421\u001b[0m, in \u001b[0;36mDataColumn.as_type\u001b[1;34m(self, new_type)\u001b[0m\n\u001b[0;32m    419\u001b[0m         casted_values\u001b[38;5;241m.\u001b[39mappend(casted_val)\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 421\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannon cast \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    422\u001b[0m col_props \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_all_properties()\n\u001b[0;32m    423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataColumn(casted_values,col_properties\u001b[38;5;241m=\u001b[39mcol_props)\n",
      "\u001b[1;31mValueError\u001b[0m: Cannon cast <function nunique.<locals>.<lambda> at 0x0000024F5A0BEDE0> to <class 'int'>: int() argument must be a string, a bytes-like object or a real number, not 'function'"
     ]
    }
   ],
   "source": [
    "df.set_property('dtype',{'person_id':int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "aaf26c83-5ce9-4cbe-a64e-b1df960cef4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | extract_date  | pay_plan  | person_id  | grade  | \n",
      "    | \u001b[31m          UNK\u001b[0m | \u001b[31m      UNK\u001b[0m | \u001b[35m       str\u001b[0m | \u001b[32m   num\u001b[0m | \n",
      "  i |             *\u001b[31m\u001b[0m |         *\u001b[31m\u001b[0m |    nunique\u001b[31m\u001b[0m |   mean\u001b[31m\u001b[0m | \n",
      "-------------------------------------------------------\n",
      "  0 | 01/01/2024 00 |        EE | "
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to function.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[99], line 838\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[1;34m(self, start_row, nrows, show_index)\u001b[0m\n\u001b[0;32m    836\u001b[0m         text_to_print\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol_val[:col_width]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol_width\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    837\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 838\u001b[0m         text_to_print\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol_val\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol_width\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28mprint\u001b[39m(text_to_print,end \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    840\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported format string passed to function.__format__"
     ]
    }
   ],
   "source": [
    "df.show(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3ba02dad-d51b-4572-9881-062ba9fbfbae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12/01/2023 00:00:00'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['extract_date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74c252d-4213-49ae-9144-e4ddc62ce7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
