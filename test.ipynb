{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b92afb8-da0a-41f5-8ee6-0751a3d435bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import operator\n",
    "import itertools as it\n",
    "import datetime\n",
    "import statistics\n",
    "from collections import defaultdict\n",
    "\n",
    "ALLOWED_COL_PROPERTIES = ['dtype','long_name','col_print_length','key','aggregation_func']\n",
    "\n",
    "def pretty_string(string,color,length=None):\n",
    "    \"\"\"Trim to length and change color of provided string.\n",
    "\n",
    "    Given string is first trimmed to requested length, then color\n",
    "    formatting is applied and the result returned.\n",
    "    Trimming is performed by keepting the first [length] characters.\n",
    "    It is useful to trim strings before formatting because\n",
    "    formatting is performed by adding special characters thus\n",
    "    making the string's length more than the visible characters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    string : str\n",
    "             String which will be returned trimmed and formatted.\n",
    "    color : str\n",
    "            Color to apply to the string. Available colors are\n",
    "            red, green, yellow, blue, magenta, cyan.\n",
    "    length : int\n",
    "             Length to which the provided string will be trimmed\n",
    "             be removing characters from the right. This length\n",
    "             is for the visible characters only and does not count\n",
    "             the special formatting characters that are added\n",
    "             by this function.\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    Given string 'lengthy_column_name' apply blue font and return\n",
    "    string that is only 4 characters long i.e. \"leng\"\n",
    "    \n",
    "    >>> pretty_string('lengthy_column_name','blue',4)\n",
    "\n",
    "    \"\"\"\n",
    "    colors_dict = {\n",
    "        'red':31,\n",
    "        'green':32,\n",
    "        'yellow':33,\n",
    "        'blue':34,\n",
    "        'magenta':35,\n",
    "        'cyan':36,\n",
    "    }\n",
    "    # This assures that only the visible characters are trimmed and not the whole string including formatting\n",
    "    if length==None:\n",
    "        return f\"\\033[{colors_dict[color]}m{string}\\033[0m\"\n",
    "    else:\n",
    "        return f\"\\033[{colors_dict[color]}m{string[:length]}\\033[0m\"\n",
    "    \n",
    "def is_iterable(obj):\n",
    "    \"\"\"Check whether obj is iterable.\"\"\"\n",
    "    try:\n",
    "        iter(obj)\n",
    "        return True\n",
    "    except TypeError:\n",
    "        return False\n",
    "\n",
    "def element_wise_comparison(func, list_1, list_2):\n",
    "    \"\"\"Compare list_1 and list_2 using func and return a list of Bool\n",
    "\n",
    "    Takes Python lists or tuples and outputs Python lists. list_2 may be a scalar.\n",
    "\n",
    "    \"\"\"\n",
    "    if not is_iterable(list_1):\n",
    "        raise TypeError(\"list_1 must be of the type 'List'\")\n",
    "    if isinstance(list_2, (int, float, str, datetime.datetime)) :\n",
    "        # Compare list list_1 to a value list_2\n",
    "        return [func(x,list_2) for x in list_1]\n",
    "    elif is_iterable(list_2):\n",
    "        # Compare list to a list if their lengths are compatible\n",
    "        if len(list_1) != len(list_2):\n",
    "            raise ValueError(\"Lists have incompatible lengths\")\n",
    "        return [func(x,y) for x, y in zip(iter(list_1), iter(list_2))]\n",
    "    else:\n",
    "        raise TypeError(\"Can only compare against the types 'Int,' 'Float,' 'Str,' or 'List'\")\n",
    "\n",
    "class Category:\n",
    "    \"\"\"Data format for categorical data\n",
    "\n",
    "    INCOMPLETE.  Will include list of categories and dict for encoding.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        return None\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.data\n",
    "        \n",
    "    def __format__(self,fmt):\n",
    "        return f\"{self.data:{fmt}}\"\n",
    "\n",
    "class DataColumn:\n",
    "    \"\"\"Represents a column of a DataFrame.\n",
    "\n",
    "    Stores the column's values and additional metadata\n",
    "    to describe column properties. DataColumn is subscriptable.\n",
    "    See examples below.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    data : list\n",
    "           Ordered ist of values belonging to this column.\n",
    "    dtype : data type\n",
    "            The type of the data in this column. For example\n",
    "            str, int, Category.\n",
    "    long_name : str\n",
    "                Long name of the column intended for human\n",
    "                understanding. Long_names can be useful\n",
    "                for interpreting each column as the names\n",
    "                that arae printed by DataFrame by default\n",
    "                are short names and should emphasize brevity\n",
    "                over meaningfulness.\n",
    "    col_print_length : int\n",
    "                The lengh (in number of characters) used when\n",
    "                printing this column. Column label and values\n",
    "                will be truncated to fit this length. \n",
    "                Calculaated by considering the min and max\n",
    "                column widths as well as the column name\n",
    "                and all values in the column.\n",
    "    key : bool\n",
    "          Boolean value indicating whether this column\n",
    "          is a key or not. Key columns may not have missing \n",
    "          values and are used by the DataFrame for aggregations.\n",
    "          Key columns are ignored when DataFrame exports data\n",
    "          for analysis by default.\n",
    "    aggregation_func : callable\n",
    "                A callable that must accept an iterable\n",
    "                and return a single value. This is used \n",
    "                by DataFrame to aggregate the data.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    apply(func):\n",
    "    min()\n",
    "    max()\n",
    "    mean()\n",
    "    median()\n",
    "    median_low()\n",
    "    median_high()\n",
    "    mode()\n",
    "    std()\n",
    "    var()\n",
    "    pstd()\n",
    "    pvariance()\n",
    "    cov()\n",
    "    cor()\n",
    "    lr(other)\n",
    "    set_type(new_type)\n",
    "    isna()\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    Create new column with four values:\n",
    "    >>> col = DataColumn([0,9,8,7])\n",
    "    Select first two elements from column's data:\n",
    "    >>> col[:2]\n",
    "    Returns list [0,9].\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, data, col_properties:dict=None):\n",
    "        \"\"\"Initiate new column\n",
    "        \n",
    "        New column containing the provided data and properties,\n",
    "        if provided. If no col_properties is passed, initiates \n",
    "        all column properties with the value of None.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : list\n",
    "               List of the column's values.\n",
    "        col_properties : dict\n",
    "                         Property: value pairs. \n",
    "        \n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        # Initiate empty properites\n",
    "        for prop in ALLOWED_COL_PROPERTIES:\n",
    "            self._set_properties({prop:None})\n",
    "        # Set the passed properties\n",
    "        if col_properties != None:\n",
    "            self._set_properties(col_properties)\n",
    "        return\n",
    "            \n",
    "    def _set_properties(self, property_dict):\n",
    "        \"\"\"Set column property\"\"\"\n",
    "        if isinstance(property_dict, dict):\n",
    "            for attr_name, attr_val in property_dict.items():\n",
    "                setattr(self, attr_name, attr_val)\n",
    "        else:\n",
    "            raise TypeError(\"property_dict parameter must be of the type 'Dict'\")\n",
    "\n",
    "    def _get_property(self, property_name):\n",
    "        \"\"\"Extract a property value\"\"\"\n",
    "        try:\n",
    "            return getattr(self,property_name,None)\n",
    "        except:\n",
    "            raise ValueError(f\"Property {property_name} not found\")\n",
    "\n",
    "    def _get_all_properties(self):\n",
    "        \"\"\"\n",
    "        Extract all properties\n",
    "        \n",
    "        Form a dicct of dicts that can be used to recreate this column i.e. in DataColumn\n",
    "        class initialization.\n",
    "        \n",
    "        \"\"\"\n",
    "        all_properties = {}\n",
    "        for prop in ALLOWED_COL_PROPERTIES:\n",
    "            all_properties[prop] = self._get_property(prop)\n",
    "        return all_properties\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.data[key]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __add__(self, other):\n",
    "        if isinstance(other, int) or isinstance(other, float):\n",
    "            return DataColumn([operator.add(x, other) for x in self.data])\n",
    "        elif is_iterable(other):\n",
    "            if len(self) != len(other):\n",
    "                raise ValueError(\"Columns have incompatible lengths\")\n",
    "            return DataColumn([x + y for x, y in zip(iter(self),iter(other))])\n",
    "        else:\n",
    "            raise TypeError(\"Operands must be iterable or 'Int,' or 'Float'\")\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        if isinstance(other, int) or isinstance(other, float):\n",
    "            return DataColumn([operator.sub(x, other) for x in self.data])\n",
    "        elif is_iterable(other):\n",
    "            if len(self) != len(other):\n",
    "                raise ValueError(\"Columns have incompatible lengths\")\n",
    "            return DataColumn([x - y for x, y in zip(iter(self),iter(other))])\n",
    "        else:\n",
    "            raise TypeError(\"Operands must be iterable or 'Int,' or 'Float'\")\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        if isinstance(other, int) or isinstance(other, float):\n",
    "            return DataColumn([operator.mul(x, other) for x in self.data])\n",
    "        elif is_iterable(other):\n",
    "            if len(self) != len(other):\n",
    "                raise ValueError(\"Columns have incompatible lengths\")\n",
    "            return DataColumn([x * y for x, y in zip(iter(self),iter(other))])\n",
    "        else:\n",
    "            raise TypeError(\"Operands must be iterable or 'Int,' or 'Float'\")\n",
    "\n",
    "    def __truediv__(self, other):\n",
    "        if isinstance(other, int) or isinstance(other, float):\n",
    "            if other==0:\n",
    "                raise ValueError(\"Div by zero is not allowed\")\n",
    "            return DataColumn([operator.truediv(x, other) for x in self.data])\n",
    "        elif is_iterable(other):\n",
    "            if len(self) != len(other):\n",
    "                raise ValueError(\"Columns have incompatible lengths\")\n",
    "            if 0 in other:\n",
    "                raise ValueError(\"Encountered division by zero\")\n",
    "            return DataColumn([x / y for x, y in zip(iter(self),iter(other))])\n",
    "        else:\n",
    "            raise TypeError(\"Can only divide by the types 'Int,' or 'Float'\")\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return DataColumn(element_wise_comparison(operator.eq,self, other))\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return DataColumn(element_wise_comparison(operator.lt,self, other))\n",
    "\n",
    "    def __le__(self, other):\n",
    "        \n",
    "        return DataColumn(element_wise_comparison(operator.le,self, other))\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        \n",
    "        return DataColumn(element_wise_comparison(operator.ne,self, other))\n",
    "\n",
    "    def __ge__(self, other):\n",
    "        \n",
    "        return DataColumn(element_wise_comparison(operator.ge,self, other))\n",
    "\n",
    "    def __gt__(self, other):\n",
    "        \n",
    "        return DataColumn(element_wise_comparison(operator.gt,self, other))\n",
    "        \n",
    "    def __repr__(self):\n",
    "        print(self.data[:5])\n",
    "        return \"Column\"\n",
    "\n",
    "    def as_list(self):\n",
    "        \"\"\"Return this column's values as a list\"\"\"\n",
    "        return self.data\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.data)\n",
    "\n",
    "    def apply(self, func):\n",
    "        \"\"\"Map func onto this column's values\"\"\"\n",
    "        return DataColumn(list(map(func,self.data)))\n",
    "\n",
    "    def min(self):\n",
    "        \"\"\"Return the smallest of this column's values\"\"\"\n",
    "        return min(self.data)\n",
    "\n",
    "    def max(self):\n",
    "        \"\"\"Return the largest of this column's values\"\"\"\n",
    "        return max(self.data)\n",
    "\n",
    "    def mean(self):\n",
    "        \"\"\"Return the mean of this column's values\"\"\"\n",
    "        return statistics.mean(self.data)\n",
    "\n",
    "    def median(self):\n",
    "        \"\"\"Return the median of this column's values\"\"\"\n",
    "        return statistics.median(self.data)\n",
    "\n",
    "    def median_low(self):\n",
    "        \"\"\"Return the low median of this column's values\"\"\"\n",
    "        return statistics.median_low(self.data)\n",
    "\n",
    "    def median_high(self):\n",
    "        \"\"\"Return the high median of this column's values\"\"\"\n",
    "        return statistics.median_high(self.data)\n",
    "\n",
    "    def mode(self):\n",
    "        \"\"\"Return the mode of this column's values\"\"\"\n",
    "        return statistics.mode(self.data)\n",
    "\n",
    "    def std(self):\n",
    "        \"\"\"Return the sample standard deviation of this column's values\"\"\"\n",
    "        return statistics.stdev(self.data)\n",
    "\n",
    "    def var(self):\n",
    "        \"\"\"Return the sample variance of this column's values\"\"\"\n",
    "        return statistics.variance(self.data)\n",
    "\n",
    "    def pstd(self):\n",
    "        \"\"\"Return the population standard deviation of this column's values\"\"\"\n",
    "        return statistics.pstdev(self.data)\n",
    "\n",
    "    def pvariance(self):\n",
    "        \"\"\"Return the population variance of this column's values\"\"\"\n",
    "        return statistics.pvariance(self.data)\n",
    "\n",
    "    def cov(self,other):\n",
    "        \"\"\"Return the covariance of this column with other column\"\"\"\n",
    "        if isinstance(other, DataColumn):\n",
    "            return statistics.covariance(self.data,other.data)\n",
    "        else:\n",
    "            raise TypeError(\"Can only compare to another DataColumn\")\n",
    "\n",
    "    def cor(self,other):\n",
    "        \"\"\"Return the correlation of this column with other column\"\"\"\n",
    "        if isinstance(other, DataColumn):\n",
    "            return statistics.correlation(self.data,other.data)\n",
    "        else:\n",
    "            raise TypeError(\"Can only compare to another DataColumn\")\n",
    "\n",
    "    def lr(self,other):\n",
    "        \"\"\"Linear regression against another column.\n",
    "\n",
    "        Regress this column on another column and return slope and intercept.\n",
    "        https://docs.python.org/3/library/statistics.html\n",
    "\n",
    "        Returns slope, intercept\n",
    "        \"\"\"\n",
    "        if isinstance(other, DataColumn):\n",
    "            return statistics.linear_regression(other.data,self.data)\n",
    "        else:\n",
    "            raise TypeError(\"Can only compare to another DataColumn\")\n",
    "\n",
    "    def as_type(self, new_type):\n",
    "        \"\"\"Returnd DataColumn equivalent to this but with values cast to new_type\"\"\"\n",
    "        casted_values = []\n",
    "        for val in self.data:\n",
    "            try:\n",
    "                if val==None:\n",
    "                    casted_val=None\n",
    "                else:\n",
    "                    casted_val = new_type(val)\n",
    "                casted_values.append(casted_val)\n",
    "            except (TypeError, ValueError) as e:\n",
    "                raise ValueError(f\"Cannon cast {val} to {new_type}: {e}\")\n",
    "        col_props = self._get_all_properties()\n",
    "        return DataColumn(casted_values,col_properties=col_props)\n",
    "\n",
    "    def isna(self):\n",
    "        \"\"\"Return list of bools indicating missing values\"\"\"\n",
    "        return list(map(lambda x: x==None,self.data))\n",
    "\n",
    "    def fillna(self,fill_val):\n",
    "        \"\"\"Return DataColumn with fill_value in place of missing values\"\"\"\n",
    "        new_values = list(map(lambda x: fill_val if x==None else x,self.data))\n",
    "        col_props = self._get_all_properties()\n",
    "        return DataColumn(new_values,col_properties=col_props)\n",
    "        \n",
    "class DataFrame:\n",
    "    '''\n",
    "    Simplistic DataFrame\n",
    "\n",
    "    Consists of columns represented by DataColumn class.\n",
    "\n",
    "    Functions\n",
    "    ---------\n",
    "    read_csv\n",
    "    to_csv\n",
    "    apply\n",
    "\n",
    "    '''\n",
    "    def __init__(self,data=None,dtypes=None,col_properties=None):\n",
    "        \"\"\"\n",
    "        Initiate new DataFrame, either empty or from values\n",
    "        \n",
    "        Returns empty DataFrame if data is None. If data is provided,\n",
    "        populates the dataframe accordingly. If dtypes are provdied,\n",
    "        casts and sets the values accordingly. If col_properties are\n",
    "        provided, sets the properties accordingly.\n",
    "        Since dtypes can also be specified in col_properties,\n",
    "        if both dtypes and col_properties were given, returns error.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : dict {str : iterable}\n",
    "               Keys are used as names (short names) for the frame's\n",
    "               columns. Defaults to None.\n",
    "        dtypes : dict {str : type}\n",
    "                 Datatypes to use for each column. Defaults to None.\n",
    "        col_properties : dict {str : dict}\n",
    "                         For each column, provided a dict of column\n",
    "                         properties. Defaults to None.\n",
    "        \n",
    "        \"\"\"\n",
    "        dtypes_provided = isinstance(dtypes,dict)\n",
    "        col_props_provided = isinstance(col_properties,dict)\n",
    "        # Make sure that only one of dtypes and col_propperties was provided\n",
    "        # since col_properties can include dtypes.\n",
    "        if dtypes_provided and col_props_provided:\n",
    "            raise TypeError(\"Can only specify one of the parameters dtypes and col_properties\")\n",
    "        values_len = -1\n",
    "        # Set default values for internal parameters\n",
    "        #self._default_col_print_length = 10\n",
    "        self._max_col_print_length = 10\n",
    "        self._min_col_print_length = 5\n",
    "        self.rows = NestedDict(assume_sorted=True)\n",
    "        self._data = []\n",
    "        self.columns = {} # keys are short names; col_properties includes long_name\n",
    "        if data==None:\n",
    "            pass\n",
    "        elif isinstance(data,dict):\n",
    "            col_idx = 0 # iterate column index\n",
    "            for key, values in data.items():\n",
    "                # Check column lengths compatibiilty\n",
    "                if values_len == -1:\n",
    "                    values_len = len(values)\n",
    "                else:\n",
    "                    if len(values) != values_len:\n",
    "                        raise ValueError(\"Columns have incompatible lengths\")\n",
    "                # Check if dtypes were given and store data values\n",
    "                if dtypes_provided:\n",
    "                    self._data.append(DataColumn([dtypes[key](val) for val in values]))\n",
    "                    self._data[col_idx]._set_properties({'dtype':dtypes[key]})\n",
    "                elif col_props_provided:\n",
    "                    self._data.append(DataColumn(values))\n",
    "                    self._data[col_idx]._set_properties(col_properties[key])\n",
    "                else:\n",
    "                    self._data.append(DataColumn(values))\n",
    "                # Add column to columns dict\n",
    "                self.columns[key] = col_idx\n",
    "                col_idx += 1\n",
    "            self._update_col_lengths()\n",
    "        else:\n",
    "            raise TypeError(\"Data must be of the type'Dict'\")\n",
    "        return\n",
    "\n",
    "    def _update_col_lengths(self,col=None):\n",
    "        \"\"\"Update the printing width of the column\"\"\"\n",
    "        if col==None:\n",
    "            for col_label, col_idx in self.columns.items():\n",
    "                new_length = min(self._max_col_print_length,max([len(str(x))+1 for x in self._data[col_idx]]))\n",
    "                new_length = max(new_length,len(col_label)+1)\n",
    "                new_length = max(new_length,self._min_col_print_length)\n",
    "                self.set_property('col_print_length',{col_label:new_length})\n",
    "            return\n",
    "        else:\n",
    "            col_label = col\n",
    "            col_idx = self.columns[col_label]\n",
    "            new_length = min(self._max_col_print_length,max([len(str(x))+1 for x in self._data[col_idx]]))\n",
    "            new_length = max(new_length,len(col_label)+1)\n",
    "            new_length = max(new_length,self._min_col_print_length)\n",
    "            self.set_property('col_print_length',{col_label:new_length})\n",
    "            return\n",
    "            \n",
    "    def read_csv(self, file_path):\n",
    "        \"\"\"\n",
    "        Read data from a csv file.\n",
    "        \n",
    "        Populates this frame, if empty, with data read from the csv file file_path.\n",
    "        Column headers from the file will be stored as the short column names. If you\n",
    "        want to replace them, use set_short_col_names method of this frame in a consequent\n",
    "        step.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        file_path : str\n",
    "                    Path to a csv file.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Make sure this frame is empty\n",
    "        if len(self.columns) > 0:\n",
    "            raise RuntimeError(\"Attemped to overwrite current data with read_csv\")\n",
    "        # Read the file\n",
    "        with open(file_path, 'r', newline='') as file:\n",
    "            csv_reader = csv.reader(file,skipinitialspace=True) # https://docs.python.org/3/library/csv.html\n",
    "            columns = next(csv_reader)\n",
    "            for i, col_label in enumerate(columns):\n",
    "                self.columns[col_label] = i\n",
    "            data = []\n",
    "            for row in csv_reader:\n",
    "                processed_row = [None if value == '' else value for value in row]\n",
    "                data.append(processed_row)\n",
    "        self._data = list(zip(*data)) # transpose\n",
    "        # Transform into DataColumn types\n",
    "        for col_idx, col_data in enumerate(self._data):\n",
    "            self._data[col_idx] = DataColumn(col_data)\n",
    "        del data;\n",
    "        self._update_col_lengths()\n",
    "        return\n",
    "\n",
    "    def to_csv(self, file_path):\n",
    "        \"\"\"\n",
    "        Store this frame's data into a csv file\n",
    "        \n",
    "        INCOMPLETE, need to fix _data and address the questions in the comments.\n",
    "        \n",
    "        \"\"\"\n",
    "        with open(file_path, 'w', newline='') as file: # newline????\n",
    "            csv_writer = csv.writer(file) # https://docs.python.org/3/library/csv.html\n",
    "            csv_writer.writerow(list(self.columns.keys()))\n",
    "            csv_writer.writerows(self._data)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Select elements from the DataFrame\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        Assume the following DataFrame df:\n",
    "          | col_a  | col_b  |  col_val   | \n",
    "        i |    UNK |    UNK |        UNK | \n",
    "        ----------------------------------\n",
    "        0 |      1 |     10 |        0.2 | \n",
    "        1 |      1 |     10 |        0.3 | \n",
    "        2 |      1 |     10 |        0.5 | \n",
    "        3 |      1 |     10 |        0.4 | \n",
    "        4 |      1 |     10 |        0.3 | \n",
    "        ...\n",
    "        \n",
    "        Column selectors:\n",
    "        df['col_a'] - column col_a\n",
    "        To select multiple columns, use a list.  Do not use a tuple.\n",
    "        df[['col_a','col_val']] - columns col_a, col_val\n",
    "\n",
    "        Column and row selectors:\n",
    "        df[:10, ['col_a','col_b']] - first 10 rows, columns col_a, col_b\n",
    "        df[[1,4], ['col_a','col_b']] - rows 1 and 4, columns col_a, \n",
    "        df[[True,False,False,True], ] - rows 0 and 3, all columns\n",
    "        df[[1,4], ['col_a',2]] - rows 1 and 4, columns col_a, col_val\n",
    "        \n",
    "        \"\"\"\n",
    "        all_cols_properties = {}\n",
    "        if isinstance(key,tuple):\n",
    "            print('check')\n",
    "            new_data_dict = {} # Store the selected data, then use it to create and return new DataFrame\n",
    "            new_cols = []\n",
    "            use_all_cols = False\n",
    "            # Extract row selector\n",
    "            if isinstance(key[0],DataColumn):\n",
    "                row_selector = key[0].data\n",
    "            else:\n",
    "                row_selector = key[0]\n",
    "            # Extract column selector\n",
    "            ## If empty, use all columns\n",
    "            try:\n",
    "                key[1]\n",
    "            except:\n",
    "                use_all_cols=True\n",
    "            if use_all_cols:\n",
    "                new_cols = list(self.columns.keys())\n",
    "            elif isinstance(key[1],(list,tuple)):\n",
    "                # if column selector is iterable, extract values into new_cols list\n",
    "                new_cols = list(key[1])\n",
    "            else:\n",
    "                # otherwise create a list with just the one element\n",
    "                new_cols.append(key[1])\n",
    "            # Make sure that the new_list contains column labels, not indices\n",
    "            for i, col in enumerate(new_cols):\n",
    "                if isinstance(col,str):\n",
    "                    pass\n",
    "                elif isinstance(col,int):\n",
    "                    new_cols[i] = list(self.columns.keys())[col]\n",
    "                else:\n",
    "                    raise TypeError(\"Column selector must contain str or int values.\")\n",
    "            # For each selected column...\n",
    "            for col_label, col_idx in self.columns.items():\n",
    "                if col_label in new_cols:\n",
    "                    if isinstance(row_selector,list):\n",
    "                        if isinstance(row_selector[0],bool):\n",
    "                            new_data_dict[col_label] = [x for x, is_selected in zip(self._data[col_idx],row_selector) if is_selected]\n",
    "                        elif isinstance(row_selector[0],int):\n",
    "                            new_data_dict[col_label] = [self._data[col_idx][x] for x in row_selector]\n",
    "                    else:\n",
    "                        new_data_dict[col_label] = self._data[col_idx][row_selector]\n",
    "                    all_cols_properties[col_label] = self._data[col_idx]._get_all_properties()\n",
    "            return DataFrame(new_data_dict,col_properties=all_cols_properties)\n",
    "        elif isinstance(key, int):\n",
    "            return DataColumn(self._data[key])\n",
    "        elif isinstance(key, str):\n",
    "            try:\n",
    "                col_idx = self.columns[key]\n",
    "                return DataColumn(self._data[col_idx])\n",
    "            except ValueError:\n",
    "                raise KeyError(f\"Column '{key}' not found\")\n",
    "        elif isinstance(key, list):\n",
    "            new_data_dict = {} # Store the selected data, then use it to create and return new DataFrame\n",
    "            # extract values into new_cols list\n",
    "            new_cols = list(key)\n",
    "            # Make sure that the new_list contains column indices, not labels\n",
    "            for i, col in enumerate(new_cols):\n",
    "                if isinstance(col,str):\n",
    "                    new_cols[i] = self.columns[col]\n",
    "                elif isinstance(col,int):\n",
    "                    pass\n",
    "                else:\n",
    "                    raise TypeError(\"Column selector must contain str or int values.\")\n",
    "            # For each selected column...\n",
    "            for col_label, col_idx in self.columns.items():\n",
    "                if col_idx in new_cols:\n",
    "                    new_data_dict[col_label] = self._data[col_idx]\n",
    "                    all_cols_properties[col_label] = self._data[col_idx]._get_all_properties()\n",
    "            return DataFrame(new_data_dict,col_properties=all_cols_properties)\n",
    "\n",
    "    def __setitem__(self, key, new_col_values):\n",
    "        \"\"\"\n",
    "        Modify existing column or create new column.\n",
    "        \n",
    "        New values must be either DataColumn, list, int, float, str, datetime, or bool.\"\"\"\n",
    "        required_col_len = len(self._data[0])\n",
    "        if isinstance(key, str):\n",
    "            col_label = key\n",
    "            # If exists, find the column index, otherwise check if possible (corrent length) to create the column\n",
    "            if key in self.columns:\n",
    "                # Column exists\n",
    "                col_idx = self.columns[key]\n",
    "            else:\n",
    "                col_idx = len(self.columns) # b/c current length is 1 greater than current rightmost idn\n",
    "                self.columns[key] = len(self.columns)\n",
    "                self._data.append(DataColumn([None]*required_col_len))\n",
    "        elif isinstance(key, int):\n",
    "            col_idx = key\n",
    "            col_label = list(self.columns.keys())[col_idx]\n",
    "        else:\n",
    "            raise TypeError(\"Key must be of the types 'Str' or 'Int'\")\n",
    "        if isinstance(new_col_values, DataColumn):\n",
    "            if len(self._data[col_idx]) != len(new_col_values):\n",
    "                raise ValueError(\"Columns have incompatible lengths\")\n",
    "            self._data[col_idx] = new_col_values\n",
    "        elif isinstance(new_col_values, list):\n",
    "            if len(self._data[col_idx]) != len(new_col_values):\n",
    "                raise ValueError(\"Columns have incompatible lengths\")\n",
    "            # Get the properties of the column being replaced and create new column with the same properties\n",
    "            col_props = self._data[col_idx]._get_all_properties()\n",
    "            self._data[col_idx] = DataColumn(new_col_values,col_properties=col_props)\n",
    "        elif isinstance(new_col_values,(int,str,float,bool,datetime,Category)):\n",
    "            # Get the properties of the column being replaced and create new column with the same properties\n",
    "            col_props = self._data[col_idx]._get_all_properties()\n",
    "            self._data[col_idx] = DataColumn([new_col_values]*required_col_len,col_properties=col_props)\n",
    "        else:\n",
    "            raise TypeError(\"New column values must be a list, DataColumn, Str, Int, Bool, or Datetime.\")\n",
    "        self._update_col_lengths(col=col_label)\n",
    "        return\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._data[0])\n",
    "    \n",
    "    def __repr__(self):\n",
    "        # Human readable representation or informal, string, representation of the dataframe\n",
    "        return str(self.show(start_row=0,nrows=5,show_index=True)) #str(list(self._data))\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self._data)\n",
    "\n",
    "    def show(self,start_row=0,nrows=5,show_index=True):\n",
    "        \"\"\"Print the requested rows of data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        start_row : int\n",
    "                    First row to be printed, default: 0.\n",
    "        nrows : int\n",
    "                How many rows to print in total, default: 5.\n",
    "        show_index : bool\n",
    "                     Whether to print index.\n",
    "        \"\"\"\n",
    "        display_data = [] # each element to represent a row (instead of col as is in self._data\n",
    "        prefix_extra_len = len(str(start_row+nrows))-1\n",
    "        prefix_header1 = \"| \" \n",
    "        prefix_header2 = \"| \"\n",
    "        prefix_line = \"--\"\n",
    "        prefix_data = \"f'| '\"\n",
    "        # Prepare prefix\n",
    "        if show_index:\n",
    "            prefix_header1 = f\"{' ':>{1+prefix_extra_len}} |\"\n",
    "            prefix_header2 = f\"{'i':>{1+prefix_extra_len}} |\"\n",
    "            prefix_line = \"-\"*(3+prefix_extra_len)\n",
    "            prefix_data=\"f'{data_idx:>{1+prefix_extra_len}} |'\"\n",
    "        # Slice rows\n",
    "        for col in self._data:\n",
    "            col = list(it.islice(col,start_row,start_row+nrows))\n",
    "            display_data.append(col)\n",
    "        # Transpose for  printing row by row\n",
    "        display_data = list(zip(*display_data))\n",
    "        # Print header\n",
    "        ## Row 1 (short name)\n",
    "        row_1_string = \"\"\n",
    "        row_1_string += prefix_header1 + \" \"\n",
    "        for col_label, col_idx in self.columns.items():\n",
    "            col_width = self._data[col_idx].col_print_length\n",
    "            row_1_string += f\"{col_label:^{col_width}}\" + ' | '\n",
    "        print(row_1_string)\n",
    "        ## Row 2 (dtypes)\n",
    "        print(prefix_header2,end=' ')\n",
    "        for col_label, col_idx in self.columns.items():\n",
    "        #for col_prop in self.col_properties:\n",
    "            try:\n",
    "                dtype = self._data[col_idx].dtype\n",
    "                col_width = self._data[col_idx].col_print_length\n",
    "                text_to_print = \"\"\n",
    "                if dtype==str:\n",
    "                    text_to_print = pretty_string(f\"{'str':>{col_width}}\",'magenta')\n",
    "                elif dtype==int or dtype==float:\n",
    "                    text_to_print = pretty_string(f\"{'num':>{col_width}}\",'green')\n",
    "                elif dtype==Category:\n",
    "                    text_to_print = pretty_string(f\"{'C':>{col_width}}\",'yellow') ########################### Need to specify whether dummiefied already or not and how many cats\n",
    "                else:\n",
    "                    text_to_print = pretty_string(f\"{'UNK':>{col_width}}\",'red')\n",
    "                print(text_to_print,end = ' | ')\n",
    "            except:\n",
    "                pass\n",
    "        # Break line\n",
    "        print(\"\\n\"+prefix_line+(\"-\"*(len(row_1_string)-1-len(prefix_line))))\n",
    "        # Print rows, one col at a time\n",
    "        for r in range(len(display_data)):\n",
    "            data_idx = r + start_row # used in eval(prefix_data)\n",
    "            print(eval(prefix_data),end=' ')\n",
    "            for col_idx, col_val in enumerate(display_data[r]):\n",
    "                text_to_print = \"\" # text to print for the current column, formatted below\n",
    "                col_width = self._data[col_idx].col_print_length\n",
    "                if isinstance(col_val,float):\n",
    "                    text_to_print=f\"{col_val:>{col_width},.1f}\"\n",
    "                elif col_val==None:\n",
    "                    text_to_print = pretty_string(f\"{'--':>{col_width}}\",'red')\n",
    "                elif isinstance(col_val,Category):\n",
    "                    text_to_print=f\"{col_val:>{col_width}}\"\n",
    "                elif isinstance(col_val,str):\n",
    "                    text_to_print=f\"{col_val[:col_width]:>{col_width}}\"\n",
    "                else:\n",
    "                    text_to_print=f\"{col_val:>{col_width}}\"\n",
    "                print(text_to_print,end = ' | ')\n",
    "            print('')\n",
    "        # Return descriptive string\n",
    "        return f\"DataFrame with {len(self.columns)} columns and {len(self._data[0])} rows\"\n",
    "\n",
    "    def set_property(self,property_type,new_properties):\n",
    "        \"\"\"Set the values of a property for one or more columns.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        property_type : str\n",
    "                        Name of the property to be set/changed\n",
    "        new_properties : dict\n",
    "                         A dict of the form short_col_label : value\n",
    "                         to be used as the mapping of new values for\n",
    "                         the property for the column indicated\n",
    "                         by the dict's key\n",
    "        \"\"\"\n",
    "        # Check that this is a property that can be set/modified:\n",
    "        if property_type not in ALLOWED_COL_PROPERTIES:\n",
    "            raise ValueError(f\"Property_type must be one of {ALLOWED_COL_PROPERTIES}\")\n",
    "        # Make sure that dict was passed\n",
    "        if not isinstance(new_properties, dict):\n",
    "            raise TypeError(f\"New_properies must be a dict\")\n",
    "        # Iterate over dict and set each column's property to the value\n",
    "        # Column properties are stored within this DataFrame, not with Column class\n",
    "        for col_name, prop_value in new_properties.items():\n",
    "            col_idx = self.columns[col_name]\n",
    "            self._data[col_idx]._set_properties({property_type:prop_value})\n",
    "            # In addition, if dtype was changed, cast the column into the new dtype\n",
    "            if property_type == 'dtype':\n",
    "                self._data[col_idx] = self._data[col_idx].as_type(prop_value)\n",
    "        return\n",
    "\n",
    "    def set_short_col_names(self,new_names,promote_current_to_long_names=False):\n",
    "        \"\"\"\n",
    "        Set or update columns' short names.\n",
    "\n",
    "        Set short names for DataFrame's columns as indicated by new_names. In addition,\n",
    "        if promote_current_to_long_names is True, current short names will be promoted\n",
    "        to long names. Short names are used when the DataFrame is printed, they should\n",
    "        emphasize brevity over clarity.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        new_names : dict\n",
    "                    Dictionary of current and new names.\n",
    "        promote_current_to_long_names : bool\n",
    "                                        Whether to promote the current short names \n",
    "                                        to new long names. Default: False.\n",
    "\n",
    "        \"\"\"\n",
    "        # Make sure none of the new names is not already taken\n",
    "        for new_label in new_names.values():\n",
    "            if new_label in self.columns.keys():\n",
    "                raise ValueError(f\"Column {new_label} already exists\")\n",
    "        new_long_names = {}\n",
    "        if not isinstance(new_names,dict):\n",
    "            raise TypeError(\"new_names must be a dict\")\n",
    "        else:\n",
    "            for cur_label, new_label in new_names.items():\n",
    "                if promote_current_to_long_names:\n",
    "                    new_long_names[new_label] = cur_label\n",
    "                self.columns[new_label] = self.columns[cur_label]\n",
    "                del self.columns[cur_label]\n",
    "            if promote_current_to_long_names:\n",
    "                self.set_property('long_name',new_long_names)\n",
    "            # Sort column elements to the original order as indicated by the dict values (column indices)\n",
    "            self.columns = dict(sorted(self.columns.items(), key=lambda item: item[1]))\n",
    "            self._update_col_lengths()\n",
    "        return\n",
    "\n",
    "    def get_col_names(self):\n",
    "        \"\"\"Get dict of column names  (short : long)\"\"\"\n",
    "        col_names_dict = {}\n",
    "        for col_short_name, col_idx in self.columns.items():\n",
    "            try:\n",
    "                col_names_dict[col_short_name] = self.col_properties[col_idx].long_name\n",
    "            except AttributeError:\n",
    "                col_names_dict[col_short_name] = None\n",
    "        return col_names_dict\n",
    "\n",
    "    def set_row_index(self,key_col_labels):\n",
    "        \"\"\"Builds the rows property based on the list of keys key_col_labels.\n",
    "\n",
    "        The resulting rows property can be accessed via selector by listing\n",
    "        key values in their hierarchical order.\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        df = DataFrame({'col_a':['A','B','A','B'],'col_b':[0,0,1,1],'val':[1,2,3,4]})\n",
    "        Calling set_row_index(['col_a','col_b']) where col_a has unique values\n",
    "        'A' and 'B' and col_b has unique values 0 and 1\n",
    "        \"\"\"\n",
    "        key_cols = {} # map for indices\n",
    "        key_cols_idx = [] # list of indices' idx in data\n",
    "        value_cols = {}\n",
    "        value_cols_idx = []\n",
    "        # List out index labels and locations\n",
    "        for col_label in key_col_labels:\n",
    "            key_cols[col_label] = self.columns[col_label]\n",
    "            key_cols_idx.append(self.columns[col_label])\n",
    "        # List out data labels and locations\n",
    "        for col_label, col_idx in self.columns.items():\n",
    "            if col_label in key_cols:\n",
    "                continue\n",
    "            else:\n",
    "                value_cols[col_label] = col_idx\n",
    "                value_cols_idx.append(col_idx)\n",
    "        # Sort data according to the provided keys\n",
    "        sorted_data=list(zip(*sorted(zip(*df.values()),key=lambda x: [x[col] for col in key_cols_idx])))\n",
    "\n",
    "        self.rows = NestedDict(assume_sorted=True)\n",
    "        # Iterate row at a time (i.e. iterate transposed data model)\n",
    "        #for data_row in zip(*self._data):\n",
    "        #    self.rows[[data_row[dim_value] for dim_value in key_cols_idx]] = [data_row[measure_val] for measure_val in value_cols_idx]\n",
    "        for i in range(len(self._data[0])):\n",
    "            self.rows[[sorted_data[dim_value][i] for dim_value in key_cols_idx]] = i#[self._data[col][i] for col in range(len(self._data))]\n",
    "        #del self._data # most likely delete this line\n",
    "        # Recreate DataFrame using the results of this method\n",
    "        new_data = {}\n",
    "        new_col_properties = {} # nested dictionary (dict for each column)\n",
    "        col_idx = 0\n",
    "        for key_col_label, old_col_idx in key_cols.items():\n",
    "            col_data = sorted_data[old_col_idx]\n",
    "            col_props = self._data[old_col_idx]._get_all_properties()\n",
    "            col_props['key'] = True\n",
    "            new_data[key_col_label] = col_data\n",
    "            new_col_properties[key_col_label] = col_props\n",
    "            col_idx += 1\n",
    "        for value_col_label, old_col_idx in value_cols.items():\n",
    "            col_data = sorted_data[old_col_idx]\n",
    "            col_props = self._data[old_col_idx]._get_all_properties()\n",
    "            col_props['key'] = False\n",
    "            new_data[value_col_label] = col_data\n",
    "            new_col_properties[value_col_label] = col_props\n",
    "            col_idx +=1\n",
    "        resulting_data_frame = DataFrame(new_data, col_properties=new_col_properties)\n",
    "        resulting_data_frame.rows = self.rows\n",
    "        return resulting_data_frame\n",
    "\n",
    "    def aggregate(self):\n",
    "        \"\"\"Aggregates DataFrame using its keys.\n",
    "\n",
    "        Keys must be set before aggregating. Aggregation_func property\n",
    "        must also be set before aggregating.\n",
    "        This method will reshape the data by creating one record \n",
    "        for each unique key combination. Values are aggregated using \n",
    "        aggregation_func property of each column.\n",
    "        \"\"\"\n",
    "        new_data = [[] for col in self.columns.items()]\n",
    "        row_idx = 0\n",
    "        # Iterate over all unique key combinations\n",
    "        for key_values in self.rows.list_levels():\n",
    "            # Aggregate values within this key combination, one column at a time\n",
    "            for col_name, col_idx in self.columns.items():\n",
    "                # Columns marked as keys are not aggregated -- they are the keys\n",
    "                if self._data[col_idx].key:\n",
    "                    current_value = self._data[col_idx][self.rows[key_values]][0]\n",
    "                    new_data[col_idx].append(current_value)\n",
    "                else:\n",
    "                    # Apply this column's aggregation function\n",
    "                    current_values = self._data[col_idx][self.rows[key_values]]\n",
    "                    new_value = self._data[col_idx].aggregation_func(current_values)\n",
    "                    new_data[col_idx].append(new_value)\n",
    "            self.rows[key_values] = row_idx\n",
    "            row_idx += 1\n",
    "        # Recreate dataframe one column at a time\n",
    "        for col_label, col_idx in self.columns.items():\n",
    "            new_col_data = new_data[col_idx]\n",
    "            new_col_props = self._data[col_idx]._get_all_properties()\n",
    "            self._data[col_idx] = DataColumn(new_col_data,col_properties=new_col_props)\n",
    "        return\n",
    "\n",
    "    def values(self):\n",
    "        \"\"\"\n",
    "        Returns a nested list of values.\n",
    "\n",
    "        The returned nested list has shape n_cols x n_rows.\n",
    "        \"\"\"\n",
    "        data_values = []\n",
    "        for col_label, col_idx in self.columns.items():\n",
    "            data_values.append(self._data[col_idx].data)\n",
    "        return data_values\n",
    "\n",
    "class NestedDict:\n",
    "    def __init__(self,assume_sorted:bool):\n",
    "        if not isinstance(assume_sorted,bool):\n",
    "            raise ValueError(\"assume_sorted must be provided as a bool\")\n",
    "        self.assume_sorted = assume_sorted\n",
    "        self.data = defaultdict(lambda: None)\n",
    "        return\n",
    "\n",
    "    def __setitem__(self, keys, value):\n",
    "        \"\"\"Build nested dictionary from keys list and value object\n",
    "\n",
    "        Each next key in keys will produce another nested dict key,\n",
    "        with the last key's value being assigned the value\n",
    "        as an element of a list.\n",
    "        If the exact specified keys already exist, the value will\n",
    "        be appended to the list value of the last key.\n",
    "        \"\"\"\n",
    "        if len(keys)>1:\n",
    "            if not keys[0] in self.data:\n",
    "                self.data[keys[0]] = NestedDict(self.assume_sorted)\n",
    "            self.data[keys[0]][keys[1:]] = value\n",
    "        else:\n",
    "            if not self.assume_sorted:\n",
    "                # Collect list of indices\n",
    "                if isinstance(self.data[keys[0]] ,list):\n",
    "                    self.data[keys[0]].append(value)\n",
    "                else:\n",
    "                    self.data[keys[0]] = [value]\n",
    "            else:\n",
    "                # Build slicer objects\n",
    "                if isinstance(self.data[keys[0]] ,slice):\n",
    "                    self.data[keys[0]] = slice(self.data[keys[0]].start,value+1) # Replaces existing slice with new one by keeping the same start but modifying the end. This works because data is sorted\n",
    "                else:\n",
    "                    self.data[keys[0]] = slice(value,value+1)\n",
    "        return\n",
    "\n",
    "    def __getitem__(self, keys):\n",
    "        if len(keys)>1:\n",
    "            return self.data[keys[0]][keys[1:]]\n",
    "        else:\n",
    "            return self.data[keys[0]]\n",
    "\n",
    "    def labels(self):\n",
    "        return list(self.data.keys())\n",
    "\n",
    "    def list_levels(self, trail=[]):\n",
    "        \"\"\"Generate list of allkey combinations.\n",
    "        \n",
    "        All, i.e. all levels', keys are returned as a nested list.\n",
    "        Each inner list contains the keys for each key column.\n",
    "        \"\"\"\n",
    "        resulting_levels=[]\n",
    "        if isinstance(self.data[list(self.data.keys())[0]],NestedDict):\n",
    "            for key, nested_dict in self.data.items():\n",
    "                this_result = nested_dict.list_levels(trail=trail + [key])\n",
    "                resulting_levels.extend(this_result)\n",
    "        else:\n",
    "            resulting_levels = [trail + [key] for key in self.data.keys()]\n",
    "        return resulting_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad5d5a08-37a5-4b74-aa21-e276a9fd13cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 18]\n",
      "Column\n"
     ]
    }
   ],
   "source": [
    "col1 = DataColumn([1,3,8])\n",
    "col2 = DataColumn([1,1,10])\n",
    "#print(col1, col2)\n",
    "col3 = col1 + col2\n",
    "print(col3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "210bdee2-ef46-4511-8c95-d1284d82f83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, False, False]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Column"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col1 == col2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78bcca49-8416-43d4-a5c4-8ffde17261a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(iter(col1),iter(col2)):\n",
    "    print(i+j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6e6cd83-90fd-4ae7-92f5-3c74b9beda0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "for i in iter(col1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62ade5a8-5dd2-4176-bb67-d41e01b9b87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_iterable(obj):\n",
    "    try:\n",
    "        iter(obj)\n",
    "        return True\n",
    "    except TypeError:\n",
    "        return False\n",
    "\n",
    "is_iterable(col1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02db099-96d0-4528-93f0-2a6b78ecb379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "05644141-f22b-421f-92c6-c68ef7f4059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ff1bcc41-a8af-4444-a9cc-903ab77a979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.read_csv(\"input_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3a6f59a6-6c87-4013-9d34-d47082509923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | col_a  | col_b  | col_num  | long_text_col  | \n",
      "i | \u001b[31m   UNK\u001b[0m | \u001b[31m   UNK\u001b[0m | \u001b[31m     UNK\u001b[0m | \u001b[31m           UNK\u001b[0m | \n",
      "-------------------------------------------------\n",
      "0 |      a |      A |       11 | this is long t | \n",
      "1 |      b |      B |       21 | this is long t | \n",
      "2 |      c |      C |       13 | this is long t | \n",
      "3 |      d |      D |       23 | this is long t | \n",
      "4 |      e |      E |        8 | this is long t | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame with 4 columns and 21 rows"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "570dbddd-de86-4a2b-94c2-259c670d846f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | col_a  | col_b  | col_num  | long_text_col  | \n",
      "i | \u001b[31m   UNK\u001b[0m | \u001b[31m   UNK\u001b[0m | \u001b[31m     UNK\u001b[0m | \u001b[31m           UNK\u001b[0m | \n",
      "-------------------------------------------------\n",
      "0 |      a |      A |       11 | this is long t | \n",
      "1 |      b |      B |       21 | this is long t | \n",
      "2 |      c |      C |       13 | this is long t | \n",
      "3 |      d |      D |       23 | this is long t | \n",
      "4 |      e |      E |        8 | this is long t | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame with 4 columns and 21 rows"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9128c679-8692-4067-afee-c499799c4565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'col_a': 0, 'col_b': 1, 'col_num': 2, 'long_text_col': 3}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "abd57b9e-dbf2-4c25-80c9-40f977348125",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_property('dtype',{'col_a':str,'col_b':str,'col_num':int,'long_text_col':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "96194d02-097f-4206-957a-5ebf25ddec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_short_col_names({'long_text_col' : 'col_char'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7264b4f9-f5dc-4cf2-92b0-a24c4f864f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_property('aggregation_func',{'col_num' : statistics.mean, 'col_a' : len})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b190309d-4e2c-4ff8-a33b-d64c26585f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dtype': None,\n",
       " 'long_name': None,\n",
       " 'col_print_length': None,\n",
       " 'key': None,\n",
       " 'aggregation_func': None}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['col_b']._get_all_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e35b0617-9eaf-4ee9-be8e-020339ae2263",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col_b'] = df['col_b'].fillna('Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c61a9c8b-7673-434c-89cc-7b9b63a6094d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dtype': None,\n",
       " 'long_name': None,\n",
       " 'col_print_length': None,\n",
       " 'key': None,\n",
       " 'aggregation_func': None}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['col_num']._get_all_properties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2f25529e-c623-4575-938f-a2f64363a993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    | col_a  |  col_b   | col_num  |  col_char  | \n",
      "  i | \u001b[35m   str\u001b[0m | \u001b[31m     UNK\u001b[0m | \u001b[32m     num\u001b[0m | \u001b[35m       str\u001b[0m | \n",
      "-------------------------------------------------\n",
      "  0 |      a |        A |       11 | this is lo | \n",
      "  1 |      b |        B |       21 | this is lo | \n",
      "  2 |      c |        C |       13 | this is lo | \n",
      "  3 |      d |        D |       23 | this is lo | \n",
      "  4 |      e |        E |        8 | this is lo | \n",
      "  5 |      f |        F |       12 | this is lo | \n",
      "  6 |      g |        A |       11 | this is lo | \n",
      "  7 |      h |        B |        2 | this is  t | \n",
      "  8 |      i |        C |        2 | this is lo | \n",
      "  9 |      l |        D |       82 | this is lo | \n",
      " 10 |      m |        A |       11 | this is lo | \n",
      " 11 |      n |        B |       21 | this is lo | \n",
      " 12 |      o |        C | \u001b[31m      --\u001b[0m | this is lo | \n",
      " 13 |      p |        D |       23 | this is lo | \n",
      " 14 |      q |        E |        8 | this is lo | \n",
      " 15 |      r |        F |       12 | this is lo | \n",
      " 16 |      s |        A |       11 | this is lo | \n",
      " 17 |      t |        B |        2 | this is lo | \n",
      " 18 |      u |        C |        2 | this is lo | \n",
      " 19 |      v |        D |       82 | this is lo | \n",
      " 20 |      x |  Missing |       13 | this is lo | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DataFrame with 4 columns and 21 rows'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.show(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "aa7ca3cc-774b-4726-8d69-e9fe897d6f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.set_row_index(['col_b','col_a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e2405a64-a9fd-4946-b162-7dd757e09761",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[98], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m df\u001b[38;5;241m.\u001b[39mset_property(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maggregation_func\u001b[39m\u001b[38;5;124m'\u001b[39m,{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcol_num\u001b[39m\u001b[38;5;124m'\u001b[39m : statistics\u001b[38;5;241m.\u001b[39mmean, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcol_char\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;28mlen\u001b[39m}) \u001b[38;5;66;03m################ why\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcol_num\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcol_num\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;66;03m###############################3\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 936\u001b[0m, in \u001b[0;36mDataFrame.aggregate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m         \u001b[38;5;66;03m# Apply this column's aggregation function\u001b[39;00m\n\u001b[1;32m    935\u001b[0m         current_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[col_idx][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrows[key_values]]\n\u001b[0;32m--> 936\u001b[0m         new_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregation_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m         new_data[col_idx]\u001b[38;5;241m.\u001b[39mappend(new_value)\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrows[key_values] \u001b[38;5;241m=\u001b[39m row_idx\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "df.set_property('aggregation_func',{'col_num' : statistics.mean, 'col_char' : len}) ################ why\n",
    "df['col_num'] = df['col_num'].fillna(0)###############################3\n",
    "df.aggregate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5bda69d7-1afc-462c-a633-ce77015f839e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |  col_b   | col_a  | col_num  |  col_char  | \n",
      "i | \u001b[31m     UNK\u001b[0m | \u001b[35m   str\u001b[0m | \u001b[32m     num\u001b[0m | \u001b[35m       str\u001b[0m | \n",
      "-----------------------------------------------\n",
      "0 |        A |      a |        0 |          1 | \n",
      "1 |        A |      g |        0 |          1 | \n",
      "2 |        A |      m |        0 |          1 | \n",
      "3 |        A |      s |        0 |          1 | \n",
      "4 |        B |      b |        0 |          1 | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame with 4 columns and 21 rows"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7f79b3-32e5-40d6-8828-b7acdf582af6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
